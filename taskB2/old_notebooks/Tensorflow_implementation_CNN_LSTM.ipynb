{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\"shapes: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "    \n",
    "    print('Dataset loaded successfully')\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindow(sequence, labels, winSize, step, noNull):\n",
    "\n",
    "    # Verify the inputs\n",
    "    try: it = iter(sequence)\n",
    "    except TypeError:\n",
    "        raise Exception(\"**ERROR** sequence must be iterable.\")\n",
    "    if not ((type(winSize) == type(0)) and (type(step) == type(0))):\n",
    "        raise Exception(\"**ERROR** type(winSize) and type(step) must be int.\")\n",
    "    if step > winSize:\n",
    "        raise Exception(\"**ERROR** step must not be larger than winSize.\")\n",
    "    if winSize > len(sequence):\n",
    "        raise Exception(\"**ERROR** winSize must not be larger than sequence length.\")\n",
    " \n",
    "    # number of chunks\n",
    "    numOfChunks = ((len(sequence)-winSize)//step)+1\n",
    " \n",
    "    # Do the work\n",
    "    for i in range(0,numOfChunks*step,step):\n",
    "        segment = sequence[i:i+winSize]\n",
    "        seg_labels = labels[i:i+winSize]\n",
    "        if noNull:\n",
    "            if seg_labels[-1] != 0:\n",
    "                yield segment, seg_labels\n",
    "        else:\n",
    "            yield segment, seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_data(X_train, y_train, X_test, y_test, winSize, step, noNull=False):\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_test) == len(y_test)\n",
    "    # obtain chunks of data\n",
    "    train_chunks = slidingWindow(X_train, y_train , winSize, step, noNull)\n",
    "    test_chunks = slidingWindow(X_test, y_test, winSize, step, noNull)\n",
    "    \n",
    "    # segment the data\n",
    "    train_segments = []\n",
    "    train_labels = []\n",
    "    for chunk in train_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        train_segments.append(data)\n",
    "        train_labels.append(labels[-1])\n",
    "    \n",
    "    test_segments = []\n",
    "    test_labels = []\n",
    "    for chunk in test_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        test_segments.append(data)\n",
    "        test_labels.append(labels[-1])\n",
    "        \n",
    "    return np.array(train_segments), np.array(train_labels), np.array(test_segments), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network params and data elaboration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sensors = 113 # number of sensor channels\n",
    "num_classes = 18 # number of classes \n",
    "window_size = 24 # window size\n",
    "step_size = 12 # half of the sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: train (557963, 113), test (118750, 113)\n",
      "Dataset loaded successfully\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_dataset('oppChallenge_gestures.data')\n",
    "\n",
    "train_segments, train_labels, test_segments, test_labels = segment_data(X_train, y_train, X_test, y_test,\n",
    "                                                                        window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46495, 24, 113)\n"
     ]
    }
   ],
   "source": [
    "print(train_segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding of labels\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels.reshape(-1,1)).toarray()\n",
    "test_labels = encoder.transform(test_labels.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46495, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# understanding batches\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert inputs.shape[0] == targets.shape[0]\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_layer(prev_layer, num_filters, kernel, strides):\n",
    "    return tf.layers.conv2d(prev_layer, num_filters, kernel, strides=strides, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_layers(prev_layer, lstm_size):\n",
    "    rnn_layers = [tf.nn.rnn_cell.BasicLSTMCell(size, activation=tf.nn.tanh) for size in [lstm_size, lstm_size]]\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    \n",
    "    return tf.nn.dynamic_rnn(cell=multi_rnn_cell, inputs=prev_layer, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout_layer(prev_layer, hold_prob):\n",
    "    return tf.nn.dropout(prev_layer, keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_output = 8\n",
    "num_filters = 64\n",
    "lstm_size = 128\n",
    "kernel_size = (5,1)\n",
    "strides = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, window_size, num_sensors, 1])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "hold = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_1 = conv2d_layer(X, num_filters, kernel_size, strides)\n",
    "conv_2 = conv2d_layer(conv_1, num_filters, kernel_size, strides)\n",
    "conv_3 = conv2d_layer(conv_2, num_filters, kernel_size, strides)\n",
    "conv_4 = conv2d_layer(conv_3, num_filters, kernel_size, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_1 = dropout_layer(conv_4, hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped = tf.reshape(drop_1, [-1, conv_output, num_filters*num_sensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_output, states = lstm_layers(reshaped, lstm_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_output = lstm_output[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_2 = dropout_layer(last_output, hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.layers.dense(drop_2, num_classes, kernel_initializer=tf.initializers.truncated_normal(stddev=0.1),\n",
    "                          bias_initializer=tf.initializers.constant(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on epoch 1\n",
      "Test accuracy is: 0.8597959280014038\n",
      "\n",
      "\n",
      "Currently on epoch 2\n",
      "Test accuracy is: 0.8645918369293213\n",
      "\n",
      "\n",
      "Currently on epoch 3\n",
      "Test accuracy is: 0.881224513053894\n",
      "\n",
      "\n",
      "Currently on epoch 4\n",
      "Test accuracy is: 0.8650000095367432\n",
      "\n",
      "\n",
      "Currently on epoch 5\n",
      "Test accuracy is: 0.8886734843254089\n",
      "\n",
      "\n",
      "Currently on epoch 6\n",
      "Test accuracy is: 0.8787755370140076\n",
      "\n",
      "\n",
      "Currently on epoch 7\n",
      "Test accuracy is: 0.8839796185493469\n",
      "\n",
      "\n",
      "Currently on epoch 8\n",
      "Test accuracy is: 0.8953061103820801\n",
      "\n",
      "\n",
      "Currently on epoch 9\n",
      "Test accuracy is: 0.8827551007270813\n",
      "\n",
      "\n",
      "Currently on epoch 10\n",
      "Test accuracy is: 0.8922448754310608\n",
      "\n",
      "\n",
      "Currently on epoch 11\n",
      "Test accuracy is: 0.8901020288467407\n",
      "\n",
      "\n",
      "Currently on epoch 12\n",
      "Test accuracy is: 0.867959201335907\n",
      "\n",
      "\n",
      "Currently on epoch 13\n",
      "Test accuracy is: 0.8928571343421936\n",
      "\n",
      "\n",
      "Currently on epoch 14\n",
      "Test accuracy is: 0.884591817855835\n",
      "\n",
      "\n",
      "Currently on epoch 15\n",
      "Test accuracy is: 0.8974489569664001\n",
      "\n",
      "\n",
      "Currently on epoch 16\n",
      "Test accuracy is: 0.8657143115997314\n",
      "\n",
      "\n",
      "Currently on epoch 17\n",
      "Test accuracy is: 0.8828571438789368\n",
      "\n",
      "\n",
      "Currently on epoch 18\n",
      "Test accuracy is: 0.8914285898208618\n",
      "\n",
      "\n",
      "Currently on epoch 19\n",
      "Test accuracy is: 0.8871428370475769\n",
      "\n",
      "\n",
      "Currently on epoch 20\n",
      "Test accuracy is: 0.8779591917991638\n",
      "\n",
      "\n",
      "Currently on epoch 21\n",
      "Test accuracy is: 0.8922448754310608\n",
      "\n",
      "\n",
      "Currently on epoch 22\n",
      "Test accuracy is: 0.8901020288467407\n",
      "\n",
      "\n",
      "Currently on epoch 23\n",
      "Test accuracy is: 0.8898979425430298\n",
      "\n",
      "\n",
      "Currently on epoch 24\n",
      "Test accuracy is: 0.8842856884002686\n",
      "\n",
      "\n",
      "Currently on epoch 25\n",
      "Test accuracy is: 0.8956122398376465\n",
      "\n",
      "\n",
      "Currently on epoch 26\n",
      "Test accuracy is: 0.8945918083190918\n",
      "\n",
      "\n",
      "Currently on epoch 27\n",
      "Test accuracy is: 0.8903061151504517\n",
      "\n",
      "\n",
      "Currently on epoch 28\n",
      "Test accuracy is: 0.8969388008117676\n",
      "\n",
      "\n",
      "Currently on epoch 29\n",
      "Test accuracy is: 0.8979591727256775\n",
      "\n",
      "\n",
      "Currently on epoch 30\n",
      "Test accuracy is: 0.8948979377746582\n",
      "\n",
      "\n",
      "Currently on epoch 31\n",
      "Test accuracy is: 0.8920407891273499\n",
      "\n",
      "\n",
      "Currently on epoch 32\n",
      "Test accuracy is: 0.895714282989502\n",
      "\n",
      "\n",
      "Currently on epoch 33\n",
      "Test accuracy is: 0.8913265466690063\n",
      "\n",
      "\n",
      "Currently on epoch 34\n",
      "Test accuracy is: 0.8954081535339355\n",
      "\n",
      "\n",
      "Currently on epoch 35\n",
      "Test accuracy is: 0.8879591822624207\n",
      "\n",
      "\n",
      "Currently on epoch 36\n",
      "Test accuracy is: 0.9017347097396851\n",
      "\n",
      "\n",
      "Currently on epoch 37\n",
      "Test accuracy is: 0.8949999809265137\n",
      "\n",
      "\n",
      "Currently on epoch 38\n",
      "Test accuracy is: 0.8965306282043457\n",
      "\n",
      "\n",
      "Currently on epoch 39\n",
      "Test accuracy is: 0.8944898247718811\n",
      "\n",
      "\n",
      "Currently on epoch 40\n",
      "Test accuracy is: 0.8865306377410889\n",
      "\n",
      "\n",
      "Currently on epoch 41\n",
      "Test accuracy is: 0.8883673548698425\n",
      "\n",
      "\n",
      "Currently on epoch 42\n",
      "Test accuracy is: 0.8975510001182556\n",
      "\n",
      "\n",
      "Currently on epoch 43\n",
      "Test accuracy is: 0.8914285898208618\n",
      "\n",
      "\n",
      "Currently on epoch 44\n",
      "Test accuracy is: 0.8874489665031433\n",
      "\n",
      "\n",
      "Currently on epoch 45\n",
      "Test accuracy is: 0.8894897699356079\n",
      "\n",
      "\n",
      "Currently on epoch 46\n",
      "Test accuracy is: 0.8879591822624207\n",
      "\n",
      "\n",
      "Currently on epoch 47\n",
      "Test accuracy is: 0.8875510096549988\n",
      "\n",
      "\n",
      "Currently on epoch 48\n",
      "Test accuracy is: 0.9016326665878296\n",
      "\n",
      "\n",
      "Currently on epoch 49\n",
      "Test accuracy is: 0.8916326761245728\n",
      "\n",
      "\n",
      "Currently on epoch 50\n",
      "Test accuracy is: 0.8901020288467407\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5b8ec9304bc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mtot_matches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./CNN_LSTM_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[0;32m   1591\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[0;32m   1592\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1593\u001b[1;33m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m   1594\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m           self._build_eager(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1051\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batchSize = 100\n",
    "hold_prob = 0.5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        \n",
    "        for batch in iterate_minibatches(train_segments, train_labels, batchSize, True):\n",
    "            \n",
    "            batch_x, batch_y = batch\n",
    "            batch_x = np.reshape(batch_x, (-1,window_size,num_sensors,1))\n",
    "            sess.run(train,feed_dict={X:batch_x, y_true:batch_y, hold:hold_prob})\n",
    "        \n",
    "        i = 0\n",
    "        for batch in iterate_minibatches(test_segments, test_labels, batchSize):\n",
    "            \n",
    "            batch_x, batch_y = batch\n",
    "            batch_x = np.reshape(batch_x, (-1,window_size,num_sensors,1))\n",
    "            \n",
    "            pred = y_pred.eval(feed_dict={X:batch_x, y_true:batch_y, hold:1.0})\n",
    "  \n",
    "            matches = np.equal(np.argmax(pred,1),np.argmax(batch_y,1))\n",
    "            matches = matches.astype(np.float32)\n",
    "         \n",
    "            if i == 0:\n",
    "                tot_matches = matches\n",
    "            else:    \n",
    "                tot_matches = np.concatenate([tot_matches, matches], axis=0)\n",
    "            i=i+1\n",
    "\n",
    "        print('Currently on epoch {}'.format(ep+1))\n",
    "        print('Test accuracy is: {}'.format(np.mean(tot_matches)))\n",
    "        print('\\n')\n",
    "        del tot_matches\n",
    "            \n",
    "saver.save(sess, \"./CNN_LSTM_model\")\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
