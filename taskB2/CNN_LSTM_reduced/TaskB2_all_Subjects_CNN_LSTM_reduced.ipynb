{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, LSTM, CuDNNLSTM, Flatten, Dropout, Reshape, BatchNormalization, PReLU, ELU\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindow(sequence, labels, winSize, step, noNull):\n",
    "\n",
    "    # Verify the inputs\n",
    "    try: it = iter(sequence)\n",
    "    except TypeError:\n",
    "        raise Exception(\"**ERROR** sequence must be iterable.\")\n",
    "    if not ((type(winSize) == type(0)) and (type(step) == type(0))):\n",
    "        raise Exception(\"**ERROR** type(winSize) and type(step) must be int.\")\n",
    "    if step > winSize:\n",
    "        raise Exception(\"**ERROR** step must not be larger than winSize.\")\n",
    "    if winSize > len(sequence):\n",
    "        raise Exception(\"**ERROR** winSize must not be larger than sequence length.\")\n",
    " \n",
    "    # number of chunks\n",
    "    numOfChunks = ((len(sequence)-winSize)//step)+1\n",
    " \n",
    "    # Do the work\n",
    "    for i in range(0,numOfChunks*step,step):\n",
    "        segment = sequence[i:i+winSize]\n",
    "        seg_labels = labels[i:i+winSize]\n",
    "        if noNull:\n",
    "            if seg_labels[-1] != 0:\n",
    "                yield segment, seg_labels\n",
    "        else:\n",
    "            yield segment, seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_data(X_train, y_train, X_val, y_val, X_test, y_test, winSize, step, noNull=False):\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_val) == len(y_val)\n",
    "    assert len(X_test) == len(y_test)\n",
    "    # obtain chunks of data\n",
    "    train_chunks = slidingWindow(X_train, y_train , winSize, step, noNull)\n",
    "    val_chunks = slidingWindow(X_val, y_val, winSize, step, noNull)\n",
    "    test_chunks = slidingWindow(X_test, y_test, winSize, step, noNull)\n",
    "    \n",
    "    # segment the data\n",
    "    train_segments = []\n",
    "    train_labels = []\n",
    "    for chunk in train_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        train_segments.append(data)\n",
    "        train_labels.append(labels[-1])\n",
    "        \n",
    "    val_segments = []\n",
    "    val_labels = []\n",
    "    for chunk in val_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        val_segments.append(data)\n",
    "        val_labels.append(labels[-1])\n",
    "    \n",
    "    test_segments = []\n",
    "    test_labels = []\n",
    "    for chunk in test_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        test_segments.append(data)\n",
    "        test_labels.append(labels[-1])\n",
    "        \n",
    "    return np.array(train_segments), np.array(train_labels), np.array(val_segments), np.array(val_labels), np.array(test_segments), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_data, val_data, test_data):\n",
    "    encoder = OneHotEncoder()\n",
    "    train_labels = encoder.fit_transform(train_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    val_labels = encoder.transform(val_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    test_labels = encoder.transform(test_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data.drop(['labels'], axis=1, inplace=True)\n",
    "    val_data.drop(['labels'], axis=1, inplace=True)\n",
    "    test_data.drop(['labels'], axis=1, inplace=True)\n",
    "    data = pd.concat([train_data,val_data,test_data])\n",
    "    scaler.fit(data)\n",
    "    train_data = scaler.transform(train_data)\n",
    "    val_data = scaler.transform(val_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train data\n",
    "adl_1_1 = pd.read_csv(\"./reduced_dataset/ADL1Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_2 = pd.read_csv(\"./reduced_dataset/ADL2Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_3 = pd.read_csv(\"./reduced_dataset/ADL3Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_4 = pd.read_csv(\"./reduced_dataset/ADL4Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_5 = pd.read_csv(\"./reduced_dataset/ADL5Opportunity_taskB2_S1.csv\",header=None)\n",
    "drill_1 = pd.read_csv(\"./reduced_dataset/Drill1Opportunity_taskB2.csv\",header=None)\n",
    "adl_2_1 = pd.read_csv(\"./reduced_dataset/ADL1Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_2_2 = pd.read_csv(\"./reduced_dataset/ADL2Opportunity_taskB2_S2.csv\",header=None)\n",
    "drill_2 = pd.read_csv(\"./reduced_dataset/Drill2Opportunity_taskB2.csv\",header=None)\n",
    "adl_3_1 = pd.read_csv(\"./reduced_dataset/ADL1Opportunity_taskB2_S3.csv\",header=None)\n",
    "adl_3_2 = pd.read_csv(\"./reduced_dataset/ADL2Opportunity_taskB2_S3.csv\",header=None)\n",
    "drill_3 = pd.read_csv(\"./reduced_dataset/Drill3Opportunity_taskB2.csv\",header=None)\n",
    "\n",
    "# import validation data\n",
    "adl_2_3 = pd.read_csv(\"./reduced_dataset/ADL3Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_3_3 = pd.read_csv(\"./reduced_dataset/ADL3Opportunity_taskB2_S3.csv\",header=None)\n",
    "\n",
    "# import test data\n",
    "adl_2_4 = pd.read_csv(\"./reduced_dataset/ADL4Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_2_5 = pd.read_csv(\"./reduced_dataset/ADL5Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_3_4 = pd.read_csv(\"./reduced_dataset/ADL4Opportunity_taskB2_S3.csv\",header=None)\n",
    "adl_3_5 = pd.read_csv(\"./reduced_dataset/ADL5Opportunity_taskB2_S3.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_frames = [adl_1_1,adl_1_2,adl_1_3,adl_1_4,adl_1_5,drill_1,adl_2_1,adl_2_2,drill_2,adl_3_1,adl_3_2,drill_3]\n",
    "val_frames = [adl_2_3,adl_3_3]\n",
    "test_frames = [adl_2_4,adl_2_5,adl_3_4,adl_3_5]\n",
    "train_data = pd.concat(train_frames)\n",
    "val_data = pd.concat(val_frames)\n",
    "test_data = pd.concat(test_frames)\n",
    "train_data.rename(columns ={21: 'labels'}, inplace =True)\n",
    "val_data.rename(columns ={21: 'labels'}, inplace =True)\n",
    "test_data.rename(columns ={21: 'labels'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: train (497014, 22), val (60949, 22), test (118750, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"shapes: train {0}, val {1}, test {2}\".format(train_data.shape, val_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_train, scaled_val, scaled_test, train_labels, val_labels, test_labels = prepare_data(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497014, 21)\n",
      "(497014, 18)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sensors = 21\n",
    "window_size = 24\n",
    "step_size = 12\n",
    "classes = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_segments, train_labels, val_segments, val_labels, test_segments, test_labels = segment_data(scaled_train, train_labels, scaled_val, val_labels,\n",
    "                                                                                                  scaled_test, test_labels, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape input for CNN\n",
    "reshaped_train = train_segments.reshape(-1, window_size, num_sensors, 1)\n",
    "reshaped_val = val_segments.reshape(-1, window_size, num_sensors, 1)\n",
    "reshaped_test = test_segments.reshape(-1, window_size, num_sensors, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "size_of_kernel = (5,1)\n",
    "kernel_strides = 1\n",
    "num_filters = 64\n",
    "num_lstm_cells = 128\n",
    "dropout_prob = 0.5\n",
    "inputshape = (window_size, num_sensors, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization(input_shape=inputshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal', name='1_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal',name='2_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal', name='3_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal', name='4_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Reshape((8, num_filters*num_sensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(CuDNNLSTM(num_lstm_cells,kernel_initializer='glorot_normal', return_sequences=True, name='1_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='1_dropout_layer'))\n",
    "\n",
    "model.add(CuDNNLSTM(num_lstm_cells,kernel_initializer='glorot_normal',return_sequences=False, name='2_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='2_dropout_layer'))\n",
    "\n",
    "model.add(Dense(64,kernel_initializer='glorot_normal',\n",
    "                bias_initializer=initializers.Constant(value=0.1), name='dense2_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='3_dropout_layer'))\n",
    "\n",
    "model.add(Dense(classes,kernel_initializer='glorot_normal',\n",
    "                bias_initializer=initializers.Constant(value=0.1), activation='softmax', name='softmax_layer'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_6: input shape: (None, 24, 21, 1) output shape: (None, 24, 21, 1)\n",
      "1_conv_layer: input shape: (None, 24, 21, 1) output shape: (None, 20, 21, 64)\n",
      "2_conv_layer: input shape: (None, 20, 21, 64) output shape: (None, 16, 21, 64)\n",
      "3_conv_layer: input shape: (None, 16, 21, 64) output shape: (None, 12, 21, 64)\n",
      "4_conv_layer: input shape: (None, 12, 21, 64) output shape: (None, 8, 21, 64)\n",
      "reshape_6: input shape: (None, 8, 21, 64) output shape: (None, 8, 1344)\n",
      "1_lstm_layer: input shape: (None, 8, 1344) output shape: (None, 8, 128)\n",
      "2_dropout_layer: input shape: (None, 8, 128) output shape: (None, 8, 128)\n",
      "2_lstm_layer: input shape: (None, 8, 128) output shape: (None, 128)\n",
      "3_dropout_layer: input shape: (None, 128) output shape: (None, 128)\n",
      "dense2_layer: input shape: (None, 128) output shape: (None, 32)\n",
      "4_dropout_layer: input shape: (None, 32) output shape: (None, 32)\n",
      "softmax_layer: input shape: (None, 32) output shape: (None, 18)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(str(layer.name) + ': input shape: ' + str(layer.input_shape) + ' output shape: ' + str(layer.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41416 samples, validate on 5078 samples\n",
      "Epoch 1/50\n",
      "41416/41416 [==============================] - 12s 278us/step - loss: 0.3269 - acc: 0.8774 - val_loss: 0.5705 - val_acc: 0.8551\n",
      "Epoch 2/50\n",
      "41416/41416 [==============================] - 12s 278us/step - loss: 0.3209 - acc: 0.8810 - val_loss: 0.6011 - val_acc: 0.8511\n",
      "Epoch 3/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.3176 - acc: 0.8804 - val_loss: 0.5815 - val_acc: 0.8539\n",
      "Epoch 4/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.3122 - acc: 0.8823 - val_loss: 0.6084 - val_acc: 0.8604\n",
      "Epoch 5/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.3108 - acc: 0.8840 - val_loss: 0.6122 - val_acc: 0.8616\n",
      "Epoch 6/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.3105 - acc: 0.8837 - val_loss: 0.6250 - val_acc: 0.8523\n",
      "Epoch 7/50\n",
      "41416/41416 [==============================] - 12s 281us/step - loss: 0.2969 - acc: 0.8874 - val_loss: 0.5766 - val_acc: 0.8600\n",
      "Epoch 8/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.3031 - acc: 0.8871 - val_loss: 0.5892 - val_acc: 0.8598\n",
      "Epoch 9/50\n",
      "41416/41416 [==============================] - 12s 282us/step - loss: 0.2955 - acc: 0.8869 - val_loss: 0.6087 - val_acc: 0.8637\n",
      "Epoch 10/50\n",
      "41416/41416 [==============================] - 12s 281us/step - loss: 0.2854 - acc: 0.8920 - val_loss: 0.6244 - val_acc: 0.8610\n",
      "Epoch 11/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2817 - acc: 0.8922 - val_loss: 0.6244 - val_acc: 0.8568\n",
      "Epoch 12/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2814 - acc: 0.8927 - val_loss: 0.6435 - val_acc: 0.8533\n",
      "Epoch 13/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2828 - acc: 0.8928 - val_loss: 0.7002 - val_acc: 0.8616\n",
      "Epoch 14/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2723 - acc: 0.8976 - val_loss: 0.6102 - val_acc: 0.8643\n",
      "Epoch 15/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2679 - acc: 0.8983 - val_loss: 0.6570 - val_acc: 0.8620\n",
      "Epoch 16/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2608 - acc: 0.9025 - val_loss: 0.6581 - val_acc: 0.8574\n",
      "Epoch 17/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2632 - acc: 0.9012 - val_loss: 0.6274 - val_acc: 0.8647\n",
      "Epoch 18/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.2656 - acc: 0.9004 - val_loss: 0.6496 - val_acc: 0.8637\n",
      "Epoch 19/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2504 - acc: 0.9064 - val_loss: 0.6492 - val_acc: 0.8529\n",
      "Epoch 20/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2460 - acc: 0.9080 - val_loss: 0.6495 - val_acc: 0.8653\n",
      "Epoch 21/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2456 - acc: 0.9066 - val_loss: 0.7070 - val_acc: 0.8558\n",
      "Epoch 22/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2482 - acc: 0.9071 - val_loss: 0.6980 - val_acc: 0.8602\n",
      "Epoch 23/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2472 - acc: 0.9079 - val_loss: 0.6625 - val_acc: 0.8659\n",
      "Epoch 24/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2389 - acc: 0.9105 - val_loss: 0.7214 - val_acc: 0.8631\n",
      "Epoch 25/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2319 - acc: 0.9141 - val_loss: 0.7122 - val_acc: 0.8580\n",
      "Epoch 26/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.2413 - acc: 0.9113 - val_loss: 0.6881 - val_acc: 0.8608\n",
      "Epoch 27/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2326 - acc: 0.9145 - val_loss: 0.7042 - val_acc: 0.8683\n",
      "Epoch 28/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2162 - acc: 0.9193 - val_loss: 0.7295 - val_acc: 0.8647\n",
      "Epoch 29/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2240 - acc: 0.9179 - val_loss: 0.7271 - val_acc: 0.8657\n",
      "Epoch 30/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2126 - acc: 0.9206 - val_loss: 0.7614 - val_acc: 0.8673\n",
      "Epoch 31/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2096 - acc: 0.9236 - val_loss: 0.7113 - val_acc: 0.8641\n",
      "Epoch 32/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.2151 - acc: 0.9220 - val_loss: 0.7348 - val_acc: 0.8716\n",
      "Epoch 33/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.2096 - acc: 0.9232 - val_loss: 0.8014 - val_acc: 0.8659\n",
      "Epoch 34/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.2065 - acc: 0.9237 - val_loss: 0.8001 - val_acc: 0.8653\n",
      "Epoch 35/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.2034 - acc: 0.9262 - val_loss: 0.7809 - val_acc: 0.8592\n",
      "Epoch 36/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.2032 - acc: 0.9258 - val_loss: 0.7321 - val_acc: 0.8671\n",
      "Epoch 37/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1949 - acc: 0.9296 - val_loss: 0.8090 - val_acc: 0.8616\n",
      "Epoch 38/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1923 - acc: 0.9315 - val_loss: 0.8592 - val_acc: 0.8598\n",
      "Epoch 39/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1866 - acc: 0.9327 - val_loss: 0.8642 - val_acc: 0.8635\n",
      "Epoch 40/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.1882 - acc: 0.9318 - val_loss: 0.8575 - val_acc: 0.8639\n",
      "Epoch 41/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1879 - acc: 0.9327 - val_loss: 0.8621 - val_acc: 0.8631\n",
      "Epoch 42/50\n",
      "41416/41416 [==============================] - 12s 278us/step - loss: 0.1775 - acc: 0.9371 - val_loss: 0.8227 - val_acc: 0.8706\n",
      "Epoch 43/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1868 - acc: 0.9325 - val_loss: 0.8345 - val_acc: 0.8594\n",
      "Epoch 44/50\n",
      "41416/41416 [==============================] - 12s 278us/step - loss: 0.1833 - acc: 0.9362 - val_loss: 0.8091 - val_acc: 0.8661\n",
      "Epoch 45/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1736 - acc: 0.9387 - val_loss: 0.8793 - val_acc: 0.8661\n",
      "Epoch 46/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1677 - acc: 0.9423 - val_loss: 0.9174 - val_acc: 0.8696\n",
      "Epoch 47/50\n",
      "41416/41416 [==============================] - 12s 278us/step - loss: 0.1732 - acc: 0.9400 - val_loss: 0.8480 - val_acc: 0.8596\n",
      "Epoch 48/50\n",
      "41416/41416 [==============================] - 12s 278us/step - loss: 0.1662 - acc: 0.9430 - val_loss: 0.8787 - val_acc: 0.8659\n",
      "Epoch 49/50\n",
      "41416/41416 [==============================] - 12s 279us/step - loss: 0.1630 - acc: 0.9448 - val_loss: 0.8553 - val_acc: 0.8702\n",
      "Epoch 50/50\n",
      "41416/41416 [==============================] - 12s 280us/step - loss: 0.1629 - acc: 0.9432 - val_loss: 0.8394 - val_acc: 0.8647\n",
      "Calculating score.. \n",
      "9894/9894 [==============================] - 2s 238us/step\n",
      "[0.81751532147936756, 0.86213866990095012]\n"
     ]
    }
   ],
   "source": [
    "batchSize = 200\n",
    "train_epoches = 50\n",
    "\n",
    "model.fit(reshaped_train,train_labels,validation_data=(reshaped_val,val_labels),epochs=train_epoches,batch_size=batchSize,verbose=1)\n",
    "\n",
    "print('Calculating score.. ')\n",
    "score = model.evaluate(reshaped_test,test_labels,verbose=1)\n",
    "print(score)\n",
    "model.save('taskB2_all_Subjects_CNN_LSTM_our_elaboration_reduced.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46494 samples, validate on 9894 samples\n",
      "Epoch 1/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.2252 - acc: 0.9322 - val_loss: 0.5973 - val_acc: 0.8672\n",
      "Epoch 2/100\n",
      "46494/46494 [==============================] - 13s 281us/step - loss: 0.2034 - acc: 0.9375 - val_loss: 0.5677 - val_acc: 0.8728\n",
      "Epoch 3/100\n",
      "46494/46494 [==============================] - 13s 281us/step - loss: 0.1917 - acc: 0.9410 - val_loss: 0.5823 - val_acc: 0.8664\n",
      "Epoch 4/100\n",
      "46494/46494 [==============================] - 13s 281us/step - loss: 0.1835 - acc: 0.9430 - val_loss: 0.5860 - val_acc: 0.8794\n",
      "Epoch 5/100\n",
      "46494/46494 [==============================] - 13s 281us/step - loss: 0.1782 - acc: 0.9446 - val_loss: 0.6281 - val_acc: 0.8635\n",
      "Epoch 6/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1799 - acc: 0.9448 - val_loss: 0.5947 - val_acc: 0.8743\n",
      "Epoch 7/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1723 - acc: 0.9447 - val_loss: 0.6082 - val_acc: 0.8701\n",
      "Epoch 8/100\n",
      "46494/46494 [==============================] - 13s 282us/step - loss: 0.1637 - acc: 0.9486 - val_loss: 0.5905 - val_acc: 0.8797\n",
      "Epoch 9/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1641 - acc: 0.9487 - val_loss: 0.6065 - val_acc: 0.8790\n",
      "Epoch 10/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1591 - acc: 0.9499 - val_loss: 0.6403 - val_acc: 0.8723\n",
      "Epoch 11/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1509 - acc: 0.9513 - val_loss: 0.6457 - val_acc: 0.8777\n",
      "Epoch 12/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1582 - acc: 0.9496 - val_loss: 0.6291 - val_acc: 0.8755\n",
      "Epoch 13/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1503 - acc: 0.9523 - val_loss: 0.6549 - val_acc: 0.8776\n",
      "Epoch 14/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1410 - acc: 0.9557 - val_loss: 0.6647 - val_acc: 0.8806\n",
      "Epoch 15/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1423 - acc: 0.9562 - val_loss: 0.6363 - val_acc: 0.8832\n",
      "Epoch 16/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.1331 - acc: 0.9588 - val_loss: 0.6685 - val_acc: 0.8728\n",
      "Epoch 17/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1338 - acc: 0.9586 - val_loss: 0.6546 - val_acc: 0.8844\n",
      "Epoch 18/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1352 - acc: 0.9577 - val_loss: 0.6577 - val_acc: 0.8831\n",
      "Epoch 19/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1270 - acc: 0.9619 - val_loss: 0.6513 - val_acc: 0.8800\n",
      "Epoch 20/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1357 - acc: 0.9582 - val_loss: 0.6437 - val_acc: 0.8826\n",
      "Epoch 21/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1265 - acc: 0.9605 - val_loss: 0.6745 - val_acc: 0.8816\n",
      "Epoch 22/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1310 - acc: 0.9605 - val_loss: 0.6858 - val_acc: 0.8782\n",
      "Epoch 23/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1181 - acc: 0.9640 - val_loss: 0.6901 - val_acc: 0.8820\n",
      "Epoch 24/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1139 - acc: 0.9654 - val_loss: 0.7220 - val_acc: 0.8806\n",
      "Epoch 25/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.1095 - acc: 0.9663 - val_loss: 0.7276 - val_acc: 0.8787\n",
      "Epoch 26/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1192 - acc: 0.9643 - val_loss: 0.6853 - val_acc: 0.8860\n",
      "Epoch 27/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.1055 - acc: 0.9678 - val_loss: 0.7192 - val_acc: 0.8825\n",
      "Epoch 28/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1188 - acc: 0.9650 - val_loss: 0.7359 - val_acc: 0.8818\n",
      "Epoch 29/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1020 - acc: 0.9698 - val_loss: 0.7252 - val_acc: 0.8755\n",
      "Epoch 30/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1027 - acc: 0.9696 - val_loss: 0.7649 - val_acc: 0.8868\n",
      "Epoch 31/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.1014 - acc: 0.9692 - val_loss: 0.7648 - val_acc: 0.8808\n",
      "Epoch 32/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.1118 - acc: 0.9663 - val_loss: 0.7969 - val_acc: 0.8750\n",
      "Epoch 33/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0971 - acc: 0.9707 - val_loss: 0.7340 - val_acc: 0.8814\n",
      "Epoch 34/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0913 - acc: 0.9728 - val_loss: 0.7850 - val_acc: 0.8824\n",
      "Epoch 35/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0960 - acc: 0.9719 - val_loss: 0.7541 - val_acc: 0.8815\n",
      "Epoch 36/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0942 - acc: 0.9725 - val_loss: 0.7841 - val_acc: 0.8781\n",
      "Epoch 37/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0960 - acc: 0.9720 - val_loss: 0.7781 - val_acc: 0.8793\n",
      "Epoch 38/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0950 - acc: 0.9722 - val_loss: 0.7518 - val_acc: 0.8816\n",
      "Epoch 39/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0817 - acc: 0.9761 - val_loss: 0.8025 - val_acc: 0.8833\n",
      "Epoch 40/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0879 - acc: 0.9747 - val_loss: 0.8066 - val_acc: 0.8855\n",
      "Epoch 41/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0850 - acc: 0.9758 - val_loss: 0.7947 - val_acc: 0.8837\n",
      "Epoch 42/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0816 - acc: 0.9769 - val_loss: 0.7809 - val_acc: 0.8805\n",
      "Epoch 43/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0835 - acc: 0.9760 - val_loss: 0.7856 - val_acc: 0.8835\n",
      "Epoch 44/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0771 - acc: 0.9774 - val_loss: 0.8836 - val_acc: 0.8671\n",
      "Epoch 45/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0872 - acc: 0.9762 - val_loss: 0.8124 - val_acc: 0.8784\n",
      "Epoch 46/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0781 - acc: 0.9783 - val_loss: 0.8669 - val_acc: 0.8782\n",
      "Epoch 47/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0793 - acc: 0.9770 - val_loss: 0.8364 - val_acc: 0.8797\n",
      "Epoch 48/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0802 - acc: 0.9771 - val_loss: 0.8063 - val_acc: 0.8827\n",
      "Epoch 49/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0752 - acc: 0.9792 - val_loss: 0.8491 - val_acc: 0.8786\n",
      "Epoch 50/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0753 - acc: 0.9786 - val_loss: 0.8270 - val_acc: 0.8837\n",
      "Epoch 51/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0687 - acc: 0.9804 - val_loss: 0.8943 - val_acc: 0.8813\n",
      "Epoch 52/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0717 - acc: 0.9801 - val_loss: 0.8731 - val_acc: 0.8832\n",
      "Epoch 53/100\n",
      "46494/46494 [==============================] - 13s 282us/step - loss: 0.0728 - acc: 0.9800 - val_loss: 0.9171 - val_acc: 0.8725\n",
      "Epoch 54/100\n",
      "46494/46494 [==============================] - 13s 283us/step - loss: 0.0784 - acc: 0.9784 - val_loss: 0.8145 - val_acc: 0.8836\n",
      "Epoch 55/100\n",
      "46494/46494 [==============================] - 13s 282us/step - loss: 0.0661 - acc: 0.9812 - val_loss: 0.8517 - val_acc: 0.8786\n",
      "Epoch 56/100\n",
      "46494/46494 [==============================] - 13s 282us/step - loss: 0.0657 - acc: 0.9815 - val_loss: 0.8941 - val_acc: 0.8807\n",
      "Epoch 57/100\n",
      "46494/46494 [==============================] - 13s 282us/step - loss: 0.0652 - acc: 0.9816 - val_loss: 0.9158 - val_acc: 0.8788\n",
      "Epoch 58/100\n",
      "46494/46494 [==============================] - 13s 281us/step - loss: 0.0729 - acc: 0.9805 - val_loss: 0.8578 - val_acc: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0636 - acc: 0.9826 - val_loss: 0.8874 - val_acc: 0.8713\n",
      "Epoch 60/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0669 - acc: 0.9810 - val_loss: 0.9298 - val_acc: 0.8819\n",
      "Epoch 61/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0689 - acc: 0.9804 - val_loss: 0.8818 - val_acc: 0.8785\n",
      "Epoch 62/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0649 - acc: 0.9823 - val_loss: 0.9071 - val_acc: 0.8795\n",
      "Epoch 63/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0634 - acc: 0.9823 - val_loss: 0.8816 - val_acc: 0.8822\n",
      "Epoch 64/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0631 - acc: 0.9824 - val_loss: 0.8651 - val_acc: 0.8826\n",
      "Epoch 65/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0622 - acc: 0.9825 - val_loss: 0.9344 - val_acc: 0.8733\n",
      "Epoch 66/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0620 - acc: 0.9824 - val_loss: 0.9232 - val_acc: 0.8734\n",
      "Epoch 67/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0557 - acc: 0.9848 - val_loss: 0.8802 - val_acc: 0.8832\n",
      "Epoch 68/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0619 - acc: 0.9824 - val_loss: 0.8775 - val_acc: 0.8790\n",
      "Epoch 69/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0620 - acc: 0.9834 - val_loss: 0.9109 - val_acc: 0.8853\n",
      "Epoch 70/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0587 - acc: 0.9841 - val_loss: 0.8719 - val_acc: 0.8824\n",
      "Epoch 71/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0513 - acc: 0.9858 - val_loss: 0.9257 - val_acc: 0.8841\n",
      "Epoch 72/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0539 - acc: 0.9852 - val_loss: 0.9390 - val_acc: 0.8758\n",
      "Epoch 73/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0566 - acc: 0.9845 - val_loss: 0.9102 - val_acc: 0.8842\n",
      "Epoch 74/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0677 - acc: 0.9816 - val_loss: 0.8414 - val_acc: 0.8813\n",
      "Epoch 75/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0572 - acc: 0.9838 - val_loss: 0.9239 - val_acc: 0.8840\n",
      "Epoch 76/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0487 - acc: 0.9862 - val_loss: 0.9441 - val_acc: 0.8782\n",
      "Epoch 77/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0542 - acc: 0.9859 - val_loss: 0.9167 - val_acc: 0.8834\n",
      "Epoch 78/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0514 - acc: 0.9859 - val_loss: 0.9895 - val_acc: 0.8789\n",
      "Epoch 79/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0508 - acc: 0.9860 - val_loss: 0.9414 - val_acc: 0.8806\n",
      "Epoch 80/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0484 - acc: 0.9868 - val_loss: 0.9871 - val_acc: 0.8764\n",
      "Epoch 81/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0513 - acc: 0.9857 - val_loss: 0.9650 - val_acc: 0.8772\n",
      "Epoch 82/100\n",
      "46494/46494 [==============================] - 13s 284us/step - loss: 0.0477 - acc: 0.9872 - val_loss: 0.9860 - val_acc: 0.8778\n",
      "Epoch 83/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0573 - acc: 0.9841 - val_loss: 0.9103 - val_acc: 0.8811\n",
      "Epoch 84/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0520 - acc: 0.9857 - val_loss: 0.9264 - val_acc: 0.8793\n",
      "Epoch 85/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0510 - acc: 0.9861 - val_loss: 0.9909 - val_acc: 0.8722\n",
      "Epoch 86/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0444 - acc: 0.9886 - val_loss: 0.9641 - val_acc: 0.8815\n",
      "Epoch 87/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0485 - acc: 0.9870 - val_loss: 0.9765 - val_acc: 0.8859\n",
      "Epoch 88/100\n",
      "46494/46494 [==============================] - 13s 287us/step - loss: 0.0448 - acc: 0.9875 - val_loss: 0.9422 - val_acc: 0.8806\n",
      "Epoch 89/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0511 - acc: 0.9862 - val_loss: 0.9652 - val_acc: 0.8819\n",
      "Epoch 90/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0488 - acc: 0.9868 - val_loss: 0.9492 - val_acc: 0.8808\n",
      "Epoch 91/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0545 - acc: 0.9851 - val_loss: 0.9405 - val_acc: 0.8787\n",
      "Epoch 92/100\n",
      "46494/46494 [==============================] - 13s 287us/step - loss: 0.0454 - acc: 0.9876 - val_loss: 0.9864 - val_acc: 0.8830\n",
      "Epoch 93/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0458 - acc: 0.9877 - val_loss: 0.9814 - val_acc: 0.8809\n",
      "Epoch 94/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0448 - acc: 0.9879 - val_loss: 1.0113 - val_acc: 0.8728\n",
      "Epoch 95/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0461 - acc: 0.9874 - val_loss: 0.9656 - val_acc: 0.8822\n",
      "Epoch 96/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0409 - acc: 0.9890 - val_loss: 0.9536 - val_acc: 0.8866\n",
      "Epoch 97/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0421 - acc: 0.9885 - val_loss: 0.9932 - val_acc: 0.8854\n",
      "Epoch 98/100\n",
      "46494/46494 [==============================] - 13s 286us/step - loss: 0.0453 - acc: 0.9877 - val_loss: 0.9966 - val_acc: 0.8807\n",
      "Epoch 99/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0416 - acc: 0.9888 - val_loss: 1.0084 - val_acc: 0.8810\n",
      "Epoch 100/100\n",
      "46494/46494 [==============================] - 13s 285us/step - loss: 0.0552 - acc: 0.9849 - val_loss: 1.0283 - val_acc: 0.8769\n",
      "Calculating score.. \n",
      "9894/9894 [==============================] - 2s 225us/step\n",
      "[1.0283362723852534, 0.87689508793208004]\n"
     ]
    }
   ],
   "source": [
    "train_epoches = 100\n",
    "all_train = np.concatenate((reshaped_train, reshaped_val))\n",
    "all_labels = np.concatenate((train_labels, val_labels))\n",
    "model.fit(all_train,all_labels,validation_data=(reshaped_test,test_labels),epochs=train_epoches,batch_size=batchSize,verbose=1)\n",
    "\n",
    "print('Calculating score.. ')\n",
    "score = model.evaluate(reshaped_test,test_labels,verbose=1)\n",
    "print(score)\n",
    "model.save('taskB2_all_Subjects_CNN_LSTM_our_elaboration_reduced.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(reshaped_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy is 0.87689508793208\n",
      "0 0.832524762482 0.940791467184\n",
      "1 0.0058621386699 0.622222222222\n",
      "2 0.00960177885587 0.845360824742\n",
      "3 0.00606428138266 0.661157024793\n",
      "4 0.00838892257934 0.887573964497\n",
      "5 0.0230442692541 0.579634464752\n",
      "6 0.0161714170204 0.71186440678\n",
      "7 0.0101071356378 0.491071428571\n",
      "8 0.00778249444108 0.323699421965\n",
      "9 0.00394178289873 0.423529411765\n",
      "10 0.00424499696786 0.21686746988\n",
      "11 0.0040428542551 0.1875\n",
      "12 0.00262785526582 0.181818181818\n",
      "13 0.0067717808773 0.460317460317\n",
      "14 0.00616535273903 0.440677966102\n",
      "15 0.0100060642814 0.515337423313\n",
      "16 0.0320396199717 0.596330275229\n",
      "17 0.0106124924196 0.444444444444\n",
      "The weigths sum is 1.0\n",
      "The computed f1-score is 0.8774429202028305\n",
      "The f1-score with sklearn function is 0.8774429202028303\n",
      "Average f1-score is 0.5294554365764078\n"
     ]
    }
   ],
   "source": [
    "# F1-score measure\n",
    "from sklearn.metrics import f1_score\n",
    "num_classes = 18\n",
    "class_predictions = []\n",
    "class_true = []\n",
    "tot_labels = 0.0\n",
    "count = 0.0\n",
    "for pair in zip(predictions, test_labels):\n",
    "    class_predictions.append(np.argmax(pair[0]))\n",
    "    class_true.append(np.argmax(pair[1]))\n",
    "    if np.argmax(pair[0]) == np.argmax(pair[1]):\n",
    "        count += 1.0\n",
    "    tot_labels += 1.0\n",
    "    \n",
    "print('Standard accuracy is ' + str(count/tot_labels))    \n",
    "\n",
    "unique, counts = np.unique(class_true, return_counts=True)\n",
    "counted_labels = dict(zip(unique, counts))\n",
    "f1_scores = f1_score(class_predictions, class_true, average=None)\n",
    "\n",
    "tot_f1_score = 0.0\n",
    "weights_sum = 0.0\n",
    "for i in range(num_classes):\n",
    "    labels_class_i = counted_labels[i]\n",
    "    weight_i = labels_class_i / tot_labels\n",
    "    weights_sum += weight_i\n",
    "    tot_f1_score += f1_scores[i]*weight_i\n",
    "    print(str(i) + ' ' + str(weight_i) + ' ' + str(f1_scores[i]))\n",
    "\n",
    "    \n",
    "print('The weigths sum is ' + str(weights_sum))\n",
    "print('The computed f1-score is {}'.format(tot_f1_score))\n",
    "print('The f1-score with sklearn function is {}'.format(f1_score(class_true, class_predictions, average='weighted')))\n",
    "\n",
    "print('Average f1-score is {}'.format(np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "layer_name = 'dense2_layer'\n",
    "inter_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "network_output = inter_layer_model.predict(all_train)\n",
    "\n",
    "# PCA with certain number of principal components\n",
    "pca = PCA(n_components=12)\n",
    "pca.fit(network_output)\n",
    "new_output = pca.transform(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=12, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_labels = np.argmax(all_labels, axis=1)\n",
    "\n",
    "# train a one-vs-one multi-class support vector machine\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(new_output, svm_labels)\n",
    "\n",
    "# predict test data\n",
    "svm_pred = clf.predict(pca.transform(inter_layer_model.predict(reshaped_test)))\n",
    "\n",
    "# measure accuracy and f1-score\n",
    "num = 0.0\n",
    "den = 0.0\n",
    "new_test_labels = np.argmax(test_labels, axis=1)\n",
    "for pair in zip(svm_pred, new_test_labels):\n",
    "    if pair[0] == pair[1]:\n",
    "        num += 1.0\n",
    "    \n",
    "    den += 1.0\n",
    "    \n",
    "print('Test accuracy is: {}'.format(num / den))\n",
    "f1_scores = f1_score(svm_pred, new_test_labels, average=None)\n",
    "print('The f1-score with sklearn function is {}'.format(f1_score(new_test_labels, svm_pred, average='weighted')))\n",
    "print('Average f1-score is {}'.format(np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 0.8803315140489185\n",
      "The f1-score with sklearn function is 0.8793259574667726\n",
      "Average f1-score is 0.5377435802985444\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
