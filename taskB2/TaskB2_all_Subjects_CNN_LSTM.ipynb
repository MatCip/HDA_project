{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, LSTM, CuDNNLSTM, Flatten, Dropout, Reshape, BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindow(sequence, labels, winSize, step, noNull):\n",
    "\n",
    "    # Verify the inputs\n",
    "    try: it = iter(sequence)\n",
    "    except TypeError:\n",
    "        raise Exception(\"**ERROR** sequence must be iterable.\")\n",
    "    if not ((type(winSize) == type(0)) and (type(step) == type(0))):\n",
    "        raise Exception(\"**ERROR** type(winSize) and type(step) must be int.\")\n",
    "    if step > winSize:\n",
    "        raise Exception(\"**ERROR** step must not be larger than winSize.\")\n",
    "    if winSize > len(sequence):\n",
    "        raise Exception(\"**ERROR** winSize must not be larger than sequence length.\")\n",
    " \n",
    "    # number of chunks\n",
    "    numOfChunks = ((len(sequence)-winSize)//step)+1\n",
    " \n",
    "    # Do the work\n",
    "    for i in range(0,numOfChunks*step,step):\n",
    "        segment = sequence[i:i+winSize]\n",
    "        seg_labels = labels[i:i+winSize]\n",
    "        if noNull:\n",
    "            if seg_labels[-1] != 0:\n",
    "                yield segment, seg_labels\n",
    "        else:\n",
    "            yield segment, seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_data(X_train, y_train, X_val, y_val, X_test, y_test, winSize, step, noNull=False):\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_val) == len(y_val)\n",
    "    assert len(X_test) == len(y_test)\n",
    "    # obtain chunks of data\n",
    "    train_chunks = slidingWindow(X_train, y_train , winSize, step, noNull)\n",
    "    val_chunks = slidingWindow(X_val, y_val, winSize, step, noNull)\n",
    "    test_chunks = slidingWindow(X_test, y_test, winSize, step, noNull)\n",
    "    \n",
    "    # segment the data\n",
    "    train_segments = []\n",
    "    train_labels = []\n",
    "    for chunk in train_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        train_segments.append(data)\n",
    "        train_labels.append(labels[-1])\n",
    "        \n",
    "    val_segments = []\n",
    "    val_labels = []\n",
    "    for chunk in val_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        val_segments.append(data)\n",
    "        val_labels.append(labels[-1])\n",
    "    \n",
    "    test_segments = []\n",
    "    test_labels = []\n",
    "    for chunk in test_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        test_segments.append(data)\n",
    "        test_labels.append(labels[-1])\n",
    "        \n",
    "    return np.array(train_segments), np.array(train_labels), np.array(val_segments), np.array(val_labels), np.array(test_segments), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_data, val_data, test_data):\n",
    "    encoder = OneHotEncoder()\n",
    "    train_labels = encoder.fit_transform(train_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    val_labels = encoder.transform(val_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    test_labels = encoder.transform(test_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data.drop(['labels'], axis=1, inplace=True)\n",
    "    val_data.drop(['labels'], axis=1, inplace=True)\n",
    "    test_data.drop(['labels'], axis=1, inplace=True)\n",
    "    data = pd.concat([train_data,val_data,test_data])\n",
    "    scaler.fit(data)\n",
    "    train_data = scaler.transform(train_data)\n",
    "    val_data = scaler.transform(val_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train data\n",
    "adl_1_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL1Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL2Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL3Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_4 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL4Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_5 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL5Opportunity_taskB2_S1.csv\",header=None)\n",
    "drill_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/Drill1Opportunity_taskB2.csv\",header=None)\n",
    "adl_2_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL1Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_2_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL2Opportunity_taskB2_S2.csv\",header=None)\n",
    "drill_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/Drill2Opportunity_taskB2.csv\",header=None)\n",
    "adl_3_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL1Opportunity_taskB2_S3.csv\",header=None)\n",
    "adl_3_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL2Opportunity_taskB2_S3.csv\",header=None)\n",
    "drill_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/Drill3Opportunity_taskB2.csv\",header=None)\n",
    "\n",
    "# import validation data\n",
    "adl_2_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL3Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_3_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL3Opportunity_taskB2_S3.csv\",header=None)\n",
    "\n",
    "# import test data\n",
    "adl_2_4 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL4Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_2_5 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL5Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_3_4 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL4Opportunity_taskB2_S3.csv\",header=None)\n",
    "adl_3_5 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL5Opportunity_taskB2_S3.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_frames = [adl_1_1,adl_1_2,adl_1_3,adl_1_4,adl_1_5,drill_1,adl_2_1,adl_2_2,drill_2,adl_3_1,adl_3_2,drill_3]\n",
    "val_frames = [adl_2_3,adl_3_3]\n",
    "test_frames = [adl_2_4,adl_2_5,adl_3_4,adl_3_5]\n",
    "train_data = pd.concat(train_frames)\n",
    "val_data = pd.concat(val_frames)\n",
    "test_data = pd.concat(test_frames)\n",
    "train_data.rename(columns ={113: 'labels'}, inplace =True)\n",
    "val_data.rename(columns ={113: 'labels'}, inplace =True)\n",
    "test_data.rename(columns ={113: 'labels'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: train (497014, 114), val (60949, 114), test (118750, 114)\n"
     ]
    }
   ],
   "source": [
    "print(\"shapes: train {0}, val {1}, test {2}\".format(train_data.shape, val_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_train, scaled_val, scaled_test, train_labels, val_labels, test_labels = prepare_data(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497014, 113)\n",
      "(497014, 18)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sensors = 113\n",
    "window_size = 24\n",
    "step_size = 12\n",
    "classes = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_segments, train_labels, val_segments, val_labels, test_segments, test_labels = segment_data(scaled_train, train_labels, scaled_val, val_labels,\n",
    "                                                                                                  scaled_test, test_labels, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape input for CNN\n",
    "reshaped_train = train_segments.reshape(-1, window_size, num_sensors, 1)\n",
    "reshaped_val = val_segments.reshape(-1, window_size, num_sensors, 1)\n",
    "reshaped_test = test_segments.reshape(-1, window_size, num_sensors, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "size_of_kernel = (5,1)\n",
    "kernel_strides = 1\n",
    "num_filters = 64\n",
    "num_lstm_cells = 128\n",
    "dropout_prob = 0.5\n",
    "inputshape = (window_size, num_sensors, 1)\n",
    "from keras.layers import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(BatchNormalization(input_shape=inputshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal', name='1_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 name='2_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 name='3_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 name='4_conv_layer'))\n",
    "model.add(PReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Reshape((8, num_filters*num_sensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(CuDNNLSTM(num_lstm_cells,kernel_initializer='glorot_normal', return_sequences=True, name='1_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='2_dropout_layer'))\n",
    "\n",
    "model.add(CuDNNLSTM(num_lstm_cells,kernel_initializer='glorot_normal',return_sequences=False, name='2_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='3_dropout_layer'))\n",
    "\n",
    "model.add(Dense(int(num_lstm_cells/2),kernel_initializer='glorot_normal',\n",
    "                bias_initializer=initializers.Constant(value=0.1), name='dense_layer'))\n",
    "model.add(Dropout(dropout_prob, name='4_dropout_layer'))\n",
    "\n",
    "model.add(Dense(classes,kernel_initializer='glorot_normal',\n",
    "                bias_initializer=initializers.Constant(value=0.1),activation='softmax', name='softmax_layer'))\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_7: input shape: (None, 24, 113, 1) output shape: (None, 24, 113, 1)\n",
      "1_conv_layer: input shape: (None, 24, 113, 1) output shape: (None, 20, 113, 64)\n",
      "p_re_lu_5: input shape: (None, 20, 113, 64) output shape: (None, 20, 113, 64)\n",
      "2_conv_layer: input shape: (None, 20, 113, 64) output shape: (None, 16, 113, 64)\n",
      "p_re_lu_6: input shape: (None, 16, 113, 64) output shape: (None, 16, 113, 64)\n",
      "3_conv_layer: input shape: (None, 16, 113, 64) output shape: (None, 12, 113, 64)\n",
      "p_re_lu_7: input shape: (None, 12, 113, 64) output shape: (None, 12, 113, 64)\n",
      "4_conv_layer: input shape: (None, 12, 113, 64) output shape: (None, 8, 113, 64)\n",
      "p_re_lu_8: input shape: (None, 8, 113, 64) output shape: (None, 8, 113, 64)\n",
      "reshape_2: input shape: (None, 8, 113, 64) output shape: (None, 8, 7232)\n",
      "1_lstm_layer: input shape: (None, 8, 7232) output shape: (None, 8, 128)\n",
      "2_dropout_layer: input shape: (None, 8, 128) output shape: (None, 8, 128)\n",
      "2_lstm_layer: input shape: (None, 8, 128) output shape: (None, 128)\n",
      "3_dropout_layer: input shape: (None, 128) output shape: (None, 128)\n",
      "dense_layer: input shape: (None, 128) output shape: (None, 64)\n",
      "4_dropout_layer: input shape: (None, 64) output shape: (None, 64)\n",
      "softmax_layer: input shape: (None, 64) output shape: (None, 18)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(str(layer.name) + ': input shape: ' + str(layer.input_shape) + ' output shape: ' + str(layer.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41416 samples, validate on 5078 samples\n",
      "Epoch 1/50\n",
      "41416/41416 [==============================] - 71s 2ms/step - loss: 1.0680 - acc: 0.7245 - val_loss: 0.8704 - val_acc: 0.8304\n",
      "Epoch 2/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.6556 - acc: 0.7887 - val_loss: 0.5432 - val_acc: 0.8452\n",
      "Epoch 3/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.5171 - acc: 0.8244 - val_loss: 0.4858 - val_acc: 0.8557\n",
      "Epoch 4/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.4412 - acc: 0.8472 - val_loss: 0.4818 - val_acc: 0.8637\n",
      "Epoch 5/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.3859 - acc: 0.8635 - val_loss: 0.4890 - val_acc: 0.8637\n",
      "Epoch 6/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.3476 - acc: 0.8754 - val_loss: 0.4470 - val_acc: 0.8694\n",
      "Epoch 7/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.3205 - acc: 0.8843 - val_loss: 0.4633 - val_acc: 0.8685\n",
      "Epoch 8/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.3036 - acc: 0.8880 - val_loss: 0.4824 - val_acc: 0.8730\n",
      "Epoch 9/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.2776 - acc: 0.8973 - val_loss: 0.5259 - val_acc: 0.8789\n",
      "Epoch 10/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.2656 - acc: 0.9039 - val_loss: 0.5355 - val_acc: 0.8822\n",
      "Epoch 11/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.2408 - acc: 0.9103 - val_loss: 0.4977 - val_acc: 0.8807\n",
      "Epoch 12/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.2200 - acc: 0.9173 - val_loss: 0.5170 - val_acc: 0.8805\n",
      "Epoch 13/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.2126 - acc: 0.9207 - val_loss: 0.5696 - val_acc: 0.8820\n",
      "Epoch 14/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.1989 - acc: 0.9293 - val_loss: 0.5595 - val_acc: 0.8818\n",
      "Epoch 15/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.1922 - acc: 0.9322 - val_loss: 0.6238 - val_acc: 0.8742\n",
      "Epoch 16/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.1801 - acc: 0.9382 - val_loss: 0.6116 - val_acc: 0.8844\n",
      "Epoch 17/50\n",
      "41416/41416 [==============================] - 64s 2ms/step - loss: 0.1595 - acc: 0.9477 - val_loss: 0.6246 - val_acc: 0.8832\n",
      "Epoch 18/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.1451 - acc: 0.9520 - val_loss: 0.6245 - val_acc: 0.8844\n",
      "Epoch 19/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.1334 - acc: 0.9578 - val_loss: 0.6376 - val_acc: 0.8899\n",
      "Epoch 20/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.1202 - acc: 0.9626 - val_loss: 0.6818 - val_acc: 0.8852\n",
      "Epoch 21/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.1140 - acc: 0.9642 - val_loss: 0.6883 - val_acc: 0.8856\n",
      "Epoch 22/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.1058 - acc: 0.9664 - val_loss: 0.6824 - val_acc: 0.8872\n",
      "Epoch 23/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.1015 - acc: 0.9691 - val_loss: 0.6872 - val_acc: 0.8836\n",
      "Epoch 24/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0931 - acc: 0.9709 - val_loss: 0.7246 - val_acc: 0.8807\n",
      "Epoch 25/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0909 - acc: 0.9718 - val_loss: 0.7510 - val_acc: 0.8860\n",
      "Epoch 26/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0848 - acc: 0.9741 - val_loss: 0.7187 - val_acc: 0.8824\n",
      "Epoch 27/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0790 - acc: 0.9752 - val_loss: 0.6940 - val_acc: 0.8872\n",
      "Epoch 28/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0764 - acc: 0.9762 - val_loss: 0.8166 - val_acc: 0.8813\n",
      "Epoch 29/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0677 - acc: 0.9791 - val_loss: 0.8302 - val_acc: 0.8891\n",
      "Epoch 30/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0719 - acc: 0.9782 - val_loss: 0.8552 - val_acc: 0.8789\n",
      "Epoch 31/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0591 - acc: 0.9823 - val_loss: 0.8550 - val_acc: 0.8838\n",
      "Epoch 32/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0614 - acc: 0.9812 - val_loss: 0.8386 - val_acc: 0.8791\n",
      "Epoch 33/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0702 - acc: 0.9789 - val_loss: 0.7695 - val_acc: 0.8879\n",
      "Epoch 34/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0538 - acc: 0.9838 - val_loss: 0.8414 - val_acc: 0.8761\n",
      "Epoch 35/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0572 - acc: 0.9831 - val_loss: 0.8849 - val_acc: 0.8844\n",
      "Epoch 36/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0519 - acc: 0.9845 - val_loss: 0.8353 - val_acc: 0.8836\n",
      "Epoch 37/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0462 - acc: 0.9863 - val_loss: 0.9105 - val_acc: 0.8929\n",
      "Epoch 38/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0426 - acc: 0.9882 - val_loss: 0.8360 - val_acc: 0.8814\n",
      "Epoch 39/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0480 - acc: 0.9852 - val_loss: 0.9198 - val_acc: 0.8826\n",
      "Epoch 40/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0499 - acc: 0.9857 - val_loss: 0.8780 - val_acc: 0.8852\n",
      "Epoch 41/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0424 - acc: 0.9874 - val_loss: 0.8449 - val_acc: 0.8814\n",
      "Epoch 42/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0430 - acc: 0.9877 - val_loss: 0.8080 - val_acc: 0.8832\n",
      "Epoch 43/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0376 - acc: 0.9889 - val_loss: 0.8755 - val_acc: 0.8856\n",
      "Epoch 44/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0384 - acc: 0.9887 - val_loss: 0.8825 - val_acc: 0.8846\n",
      "Epoch 45/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0377 - acc: 0.9886 - val_loss: 0.8130 - val_acc: 0.8824\n",
      "Epoch 46/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.9289 - val_acc: 0.8858\n",
      "Epoch 47/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0342 - acc: 0.9900 - val_loss: 0.9266 - val_acc: 0.8836\n",
      "Epoch 48/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0366 - acc: 0.9896 - val_loss: 0.8146 - val_acc: 0.8840\n",
      "Epoch 49/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0318 - acc: 0.9906 - val_loss: 0.9232 - val_acc: 0.8879\n",
      "Epoch 50/50\n",
      "41416/41416 [==============================] - 63s 2ms/step - loss: 0.0386 - acc: 0.9890 - val_loss: 0.8687 - val_acc: 0.8901\n",
      "Calculating score.. \n",
      "9894/9894 [==============================] - 7s 717us/step\n",
      "[0.72783343583296201, 0.89478471801091575]\n",
      "Train on 46494 samples, validate on 9894 samples\n",
      "Epoch 1/50\n",
      "46494/46494 [==============================] - 75s 2ms/step - loss: 0.0939 - acc: 0.9787 - val_loss: 0.4357 - val_acc: 0.9076\n",
      "Epoch 2/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0663 - acc: 0.9835 - val_loss: 0.4113 - val_acc: 0.9101\n",
      "Epoch 3/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0569 - acc: 0.9838 - val_loss: 0.4989 - val_acc: 0.9059\n",
      "Epoch 4/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0484 - acc: 0.9872 - val_loss: 0.4964 - val_acc: 0.9069\n",
      "Epoch 5/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0400 - acc: 0.9883 - val_loss: 0.5152 - val_acc: 0.9076\n",
      "Epoch 6/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0395 - acc: 0.9887 - val_loss: 0.5012 - val_acc: 0.9130\n",
      "Epoch 7/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0395 - acc: 0.9882 - val_loss: 0.5733 - val_acc: 0.9024\n",
      "Epoch 8/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0386 - acc: 0.9893 - val_loss: 0.5316 - val_acc: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0359 - acc: 0.9898 - val_loss: 0.5471 - val_acc: 0.9118\n",
      "Epoch 10/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0299 - acc: 0.9915 - val_loss: 0.6065 - val_acc: 0.9116\n",
      "Epoch 11/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0332 - acc: 0.9911 - val_loss: 0.5402 - val_acc: 0.9151\n",
      "Epoch 12/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0276 - acc: 0.9917 - val_loss: 0.6069 - val_acc: 0.9080\n",
      "Epoch 13/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0299 - acc: 0.9913 - val_loss: 0.6670 - val_acc: 0.9032\n",
      "Epoch 14/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0278 - acc: 0.9923 - val_loss: 0.6303 - val_acc: 0.9119\n",
      "Epoch 15/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0328 - acc: 0.9907 - val_loss: 0.6130 - val_acc: 0.9066\n",
      "Epoch 16/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0270 - acc: 0.9926 - val_loss: 0.6786 - val_acc: 0.9077\n",
      "Epoch 17/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0244 - acc: 0.9930 - val_loss: 0.6512 - val_acc: 0.9071\n",
      "Epoch 18/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0273 - acc: 0.9924 - val_loss: 0.6157 - val_acc: 0.9089\n",
      "Epoch 19/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0254 - acc: 0.9930 - val_loss: 0.6266 - val_acc: 0.9066\n",
      "Epoch 20/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0238 - acc: 0.9933 - val_loss: 0.6897 - val_acc: 0.9095\n",
      "Epoch 21/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0241 - acc: 0.9938 - val_loss: 0.6897 - val_acc: 0.9039\n",
      "Epoch 22/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0231 - acc: 0.9937 - val_loss: 0.6494 - val_acc: 0.9060\n",
      "Epoch 23/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0220 - acc: 0.9938 - val_loss: 0.7231 - val_acc: 0.9030\n",
      "Epoch 24/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0167 - acc: 0.9953 - val_loss: 0.7227 - val_acc: 0.9060\n",
      "Epoch 25/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0221 - acc: 0.9940 - val_loss: 0.6573 - val_acc: 0.9073\n",
      "Epoch 26/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0258 - acc: 0.9925 - val_loss: 0.6232 - val_acc: 0.9086\n",
      "Epoch 27/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0218 - acc: 0.9936 - val_loss: 0.6736 - val_acc: 0.9092\n",
      "Epoch 28/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0187 - acc: 0.9951 - val_loss: 0.7187 - val_acc: 0.9077\n",
      "Epoch 29/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0218 - acc: 0.9940 - val_loss: 0.6463 - val_acc: 0.9087\n",
      "Epoch 30/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0204 - acc: 0.9946 - val_loss: 0.7146 - val_acc: 0.9059\n",
      "Epoch 31/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.7223 - val_acc: 0.9097\n",
      "Epoch 32/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0195 - acc: 0.9946 - val_loss: 0.6715 - val_acc: 0.9078\n",
      "Epoch 33/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0157 - acc: 0.9955 - val_loss: 0.6733 - val_acc: 0.9161\n",
      "Epoch 34/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0223 - acc: 0.9939 - val_loss: 0.6454 - val_acc: 0.9145\n",
      "Epoch 35/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0196 - acc: 0.9946 - val_loss: 0.6902 - val_acc: 0.9110\n",
      "Epoch 36/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0159 - acc: 0.9961 - val_loss: 0.7713 - val_acc: 0.9056\n",
      "Epoch 37/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.7400 - val_acc: 0.9116\n",
      "Epoch 38/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0243 - acc: 0.9939 - val_loss: 0.6624 - val_acc: 0.9131\n",
      "Epoch 39/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0169 - acc: 0.9955 - val_loss: 0.6975 - val_acc: 0.9060\n",
      "Epoch 40/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0162 - acc: 0.9959 - val_loss: 0.7390 - val_acc: 0.9125\n",
      "Epoch 41/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0167 - acc: 0.9956 - val_loss: 0.6675 - val_acc: 0.9088\n",
      "Epoch 42/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0204 - acc: 0.9944 - val_loss: 0.7235 - val_acc: 0.9063\n",
      "Epoch 43/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0140 - acc: 0.9961 - val_loss: 0.7298 - val_acc: 0.9047\n",
      "Epoch 44/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0170 - acc: 0.9957 - val_loss: 0.6626 - val_acc: 0.9065\n",
      "Epoch 45/50\n",
      "46494/46494 [==============================] - 144s 3ms/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.7345 - val_acc: 0.9115\n",
      "Epoch 46/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0171 - acc: 0.9952 - val_loss: 0.7809 - val_acc: 0.9047\n",
      "Epoch 47/50\n",
      "46494/46494 [==============================] - 74s 2ms/step - loss: 0.0232 - acc: 0.9941 - val_loss: 0.6545 - val_acc: 0.9091\n",
      "Epoch 48/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0149 - acc: 0.9958 - val_loss: 0.7092 - val_acc: 0.9084\n",
      "Epoch 49/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.6990 - val_acc: 0.9144\n",
      "Epoch 50/50\n",
      "46494/46494 [==============================] - 73s 2ms/step - loss: 0.0111 - acc: 0.9972 - val_loss: 0.6769 - val_acc: 0.9097\n",
      "Calculating score.. \n",
      "9894/9894 [==============================] - 7s 676us/step\n",
      "[0.67689962433628592, 0.90974327875480088]\n"
     ]
    }
   ],
   "source": [
    "batchSize = 200\n",
    "train_epoches = 50\n",
    "\n",
    "model.fit(reshaped_train,train_labels,validation_data=(reshaped_val,val_labels),epochs=train_epoches,batch_size=batchSize,verbose=1)\n",
    "\n",
    "print('Calculating score.. ')\n",
    "score = model.evaluate(reshaped_test,test_labels,verbose=1)\n",
    "print(score)\n",
    "\n",
    "train_epoches = 20\n",
    "all_train = np.concatenate((reshaped_train, reshaped_val))\n",
    "all_labels = np.concatenate((train_labels, val_labels))\n",
    "model.fit(all_train,all_labels,validation_data=(reshaped_test,test_labels),epochs=train_epoches,batch_size=batchSize,verbose=1)\n",
    "\n",
    "print('Calculating score.. ')\n",
    "score = model.evaluate(reshaped_test,test_labels,verbose=1)\n",
    "print(score)\n",
    "model.save('taskB2_all_Subjects_CNN_LSTM_our_elaboration_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(reshaped_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy is 0.9097432787548009\n",
      "0 0.832524762482 0.957392571012\n",
      "1 0.0058621386699 0.686131386861\n",
      "2 0.00960177885587 0.815642458101\n",
      "3 0.00606428138266 0.684210526316\n",
      "4 0.00838892257934 0.850828729282\n",
      "5 0.0230442692541 0.680952380952\n",
      "6 0.0161714170204 0.755852842809\n",
      "7 0.0101071356378 0.604166666667\n",
      "8 0.00778249444108 0.567010309278\n",
      "9 0.00394178289873 0.404494382022\n",
      "10 0.00424499696786 0.475\n",
      "11 0.0040428542551 0.421052631579\n",
      "12 0.00262785526582 0.436363636364\n",
      "13 0.0067717808773 0.615384615385\n",
      "14 0.00616535273903 0.594594594595\n",
      "15 0.0100060642814 0.655737704918\n",
      "16 0.0320396199717 0.721461187215\n",
      "17 0.0106124924196 0.693069306931\n",
      "The weigths sum is 1.0\n",
      "The computed f1-score is 0.909952812032923\n",
      "The f1-score with sklearn function is 0.9099528120329231\n",
      "Average f1-score is 0.6455192183492321\n"
     ]
    }
   ],
   "source": [
    "# F1-score measure\n",
    "from sklearn.metrics import f1_score\n",
    "num_classes = 18\n",
    "class_predictions = []\n",
    "class_true = []\n",
    "tot_labels = 0.0\n",
    "count = 0.0\n",
    "for pair in zip(predictions, test_labels):\n",
    "    class_predictions.append(np.argmax(pair[0]))\n",
    "    class_true.append(np.argmax(pair[1]))\n",
    "    if np.argmax(pair[0]) == np.argmax(pair[1]):\n",
    "        count += 1.0\n",
    "    tot_labels += 1.0\n",
    "    \n",
    "print('Standard accuracy is ' + str(count/tot_labels))    \n",
    "\n",
    "unique, counts = np.unique(class_true, return_counts=True)\n",
    "counted_labels = dict(zip(unique, counts))\n",
    "f1_scores = f1_score(class_predictions, class_true, average=None)\n",
    "\n",
    "tot_f1_score = 0.0\n",
    "weights_sum = 0.0\n",
    "for i in range(num_classes):\n",
    "    labels_class_i = counted_labels[i]\n",
    "    weight_i = labels_class_i / tot_labels\n",
    "    weights_sum += weight_i\n",
    "    tot_f1_score += f1_scores[i]*weight_i\n",
    "    print(str(i) + ' ' + str(weight_i) + ' ' + str(f1_scores[i]))\n",
    "\n",
    "    \n",
    "print('The weigths sum is ' + str(weights_sum))\n",
    "print('The computed f1-score is {}'.format(tot_f1_score))\n",
    "print('The f1-score with sklearn function is {}'.format(f1_score(class_true, class_predictions, average='weighted')))\n",
    "print('Average f1-score is {}'.format(np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "layer_name = 'dense_layer'\n",
    "inter_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "network_output = inter_layer_model.predict(all_train)\n",
    "\n",
    "# PCA with certain number of principal components\n",
    "pca = PCA(n_components=40)\n",
    "pca.fit(network_output)\n",
    "new_output = pca.transform(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91083123  0.92839133  0.92467139  0.90025316  0.89761784]\n",
      "Accuracy: 0.91 (+/- 0.02)\n",
      "Test accuracy is: 0.9108550636749545\n",
      "The f1-score with sklearn function is 0.9090554906798731\n",
      "Average f1-score is 0.6439139538765573\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "svm_labels = np.argmax(all_labels, axis=1)\n",
    "\n",
    "# train a one-vs-one multi-class support vector machine\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(new_output, svm_labels)\n",
    "\n",
    "# predict test data\n",
    "svm_pred = clf.predict(pca.transform(inter_layer_model.predict(reshaped_test)))\n",
    "\n",
    "# measure accuracy and f1-score\n",
    "num = 0.0\n",
    "den = 0.0\n",
    "new_test_labels = np.argmax(test_labels, axis=1)\n",
    "for pair in zip(svm_pred, new_test_labels):\n",
    "    if pair[0] == pair[1]:\n",
    "        num += 1.0\n",
    "    \n",
    "    den += 1.0\n",
    "\n",
    "scores = cross_val_score(clf, pca.transform(inter_layer_model.predict(reshaped_test)),new_test_labels, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test accuracy is: {}'.format(num / den))\n",
    "f1_scores = f1_score(svm_pred, new_test_labels, average=None)\n",
    "print('The f1-score with sklearn function is {}'.format(f1_score(new_test_labels, svm_pred, average='weighted')))\n",
    "print('Average f1-score is {}'.format(np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 0.9123711340206185\n",
      "The f1-score with sklearn function is 0.9070462523665573\n",
      "Average f1-score is 0.630115685381004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predicted = cross_val_predict(clf, pca.transform(inter_layer_model.predict(reshaped_test)),new_test_labels, cv=5)\n",
    "\n",
    "# measure accuracy and f1-score\n",
    "num = 0.0\n",
    "den = 0.0\n",
    "new_test_labels = np.argmax(test_labels, axis=1)\n",
    "for pair in zip(predicted, new_test_labels):\n",
    "    if pair[0] == pair[1]:\n",
    "        num += 1.0\n",
    "    \n",
    "    den += 1.0\n",
    "\n",
    "print('Test accuracy is: {}'.format(num / den))\n",
    "f1_scores = f1_score(predicted, new_test_labels, average=None)\n",
    "print('The f1-score with sklearn function is {}'.format(f1_score(new_test_labels, predicted, average='weighted')))\n",
    "print('Average f1-score is {}'.format(np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv('preds_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(testY)\n",
    "true_df.to_csv('true_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
