{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, LSTM, CuDNNLSTM, Flatten, Dropout, Reshape\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindow(sequence, labels, winSize, step, noNull):\n",
    "\n",
    "    # Verify the inputs\n",
    "    try: it = iter(sequence)\n",
    "    except TypeError:\n",
    "        raise Exception(\"**ERROR** sequence must be iterable.\")\n",
    "    if not ((type(winSize) == type(0)) and (type(step) == type(0))):\n",
    "        raise Exception(\"**ERROR** type(winSize) and type(step) must be int.\")\n",
    "    if step > winSize:\n",
    "        raise Exception(\"**ERROR** step must not be larger than winSize.\")\n",
    "    if winSize > len(sequence):\n",
    "        raise Exception(\"**ERROR** winSize must not be larger than sequence length.\")\n",
    " \n",
    "    # number of chunks\n",
    "    numOfChunks = ((len(sequence)-winSize)//step)+1\n",
    " \n",
    "    # Do the work\n",
    "    for i in range(0,numOfChunks*step,step):\n",
    "        segment = sequence[i:i+winSize]\n",
    "        seg_labels = labels[i:i+winSize]\n",
    "        if noNull:\n",
    "            if seg_labels[-1] != 0:\n",
    "                yield segment, seg_labels\n",
    "        else:\n",
    "            yield segment, seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_data(X_train, y_train, X_val, y_val, X_test, y_test, winSize, step, noNull=False):\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_val) == len(y_val)\n",
    "    assert len(X_test) == len(y_test)\n",
    "    # obtain chunks of data\n",
    "    train_chunks = slidingWindow(X_train, y_train , winSize, step, noNull)\n",
    "    val_chunks = slidingWindow(X_val, y_val, winSize, step, noNull)\n",
    "    test_chunks = slidingWindow(X_test, y_test, winSize, step, noNull)\n",
    "    \n",
    "    # segment the data\n",
    "    train_segments = []\n",
    "    train_labels = []\n",
    "    for chunk in train_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        train_segments.append(data)\n",
    "        train_labels.append(labels[-1])\n",
    "        \n",
    "    val_segments = []\n",
    "    val_labels = []\n",
    "    for chunk in val_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        val_segments.append(data)\n",
    "        val_labels.append(labels[-1])\n",
    "    \n",
    "    test_segments = []\n",
    "    test_labels = []\n",
    "    for chunk in test_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        test_segments.append(data)\n",
    "        test_labels.append(labels[-1])\n",
    "        \n",
    "    return np.array(train_segments), np.array(train_labels), np.array(val_segments), np.array(val_labels), np.array(test_segments), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_data, val_data, test_data):\n",
    "    encoder = OneHotEncoder()\n",
    "    train_labels = encoder.fit_transform(train_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    val_labels = encoder.transform(val_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    test_labels = encoder.transform(test_data['labels'].values.reshape(-1,1)).toarray()\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data.drop(['labels'], axis=1, inplace=True)\n",
    "    val_data.drop(['labels'], axis=1, inplace=True)\n",
    "    test_data.drop(['labels'], axis=1, inplace=True)\n",
    "    data = pd.concat([train_data,val_data,test_data])\n",
    "    scaler.fit(data)\n",
    "    train_data = scaler.transform(train_data)\n",
    "    val_data = scaler.transform(val_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    return train_data, val_data, test_data, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train data\n",
    "adl_1_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL1Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL2Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL3Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_4 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL4Opportunity_taskB2_S1.csv\",header=None)\n",
    "adl_1_5 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL5Opportunity_taskB2_S1.csv\",header=None)\n",
    "drill_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/Drill1Opportunity_taskB2.csv\",header=None)\n",
    "adl_2_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL1Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_2_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL2Opportunity_taskB2_S2.csv\",header=None)\n",
    "drill_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/Drill2Opportunity_taskB2.csv\",header=None)\n",
    "adl_3_1 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL1Opportunity_taskB2_S3.csv\",header=None)\n",
    "adl_3_2 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL2Opportunity_taskB2_S3.csv\",header=None)\n",
    "drill_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/Drill3Opportunity_taskB2.csv\",header=None)\n",
    "\n",
    "# import validation data\n",
    "adl_2_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL3Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_3_3 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL3Opportunity_taskB2_S3.csv\",header=None)\n",
    "\n",
    "# import test data\n",
    "adl_2_4 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL4Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_2_5 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL5Opportunity_taskB2_S2.csv\",header=None)\n",
    "adl_3_4 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL4Opportunity_taskB2_S3.csv\",header=None)\n",
    "adl_3_5 = pd.read_csv(\"./full_dataset/CIP_interpolation/ADL5Opportunity_taskB2_S3.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_frames = [adl_1_1,adl_1_2,adl_1_3,adl_1_4,adl_1_5,drill_1,adl_2_1,adl_2_2,drill_2,adl_3_1,adl_3_2,drill_3]\n",
    "val_frames = [adl_2_3,adl_3_3]\n",
    "test_frames = [adl_2_4,adl_2_5,adl_3_4,adl_3_5]\n",
    "train_data = pd.concat(train_frames)\n",
    "val_data = pd.concat(val_frames)\n",
    "test_data = pd.concat(test_frames)\n",
    "train_data.rename(columns ={113: 'labels'}, inplace =True)\n",
    "val_data.rename(columns ={113: 'labels'}, inplace =True)\n",
    "test_data.rename(columns ={113: 'labels'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: train (497014, 114), val (60949, 114), test (118750, 114)\n"
     ]
    }
   ],
   "source": [
    "print(\"shapes: train {0}, val {1}, test {2}\".format(train_data.shape, val_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_train, scaled_val, scaled_test, train_labels, val_labels, test_labels = prepare_data(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497014, 113)\n",
      "(497014, 18)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sensors = 113\n",
    "window_size = 24\n",
    "step_size = 12\n",
    "classes = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_segments, train_labels, val_segments, val_labels, test_segments, test_labels = segment_data(scaled_train, train_labels, scaled_val, val_labels,\n",
    "                                                                                                  scaled_test, test_labels, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape input for CNN\n",
    "reshaped_train = train_segments.reshape(-1, window_size, num_sensors, 1)\n",
    "reshaped_val = val_segments.reshape(-1, window_size, num_sensors, 1)\n",
    "reshaped_test = test_segments.reshape(-1, window_size, num_sensors, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "size_of_kernel = (5,1)\n",
    "kernel_strides = 1\n",
    "num_filters = 64\n",
    "num_lstm_cells = 128\n",
    "dropout_prob = 0.5\n",
    "inputshape = (window_size, num_sensors, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu', input_shape=inputshape,\n",
    "                 kernel_initializer='glorot_normal', name='1_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu',kernel_initializer='glorot_normal',\n",
    "                 name='2_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu',kernel_initializer='glorot_normal',\n",
    "                 name='3_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu',kernel_initializer='glorot_normal',\n",
    "                 name='4_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Reshape((8, num_filters*num_sensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(CuDNNLSTM(num_lstm_cells,kernel_initializer='glorot_normal', return_sequences=True, name='1_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='2_dropout_layer'))\n",
    "\n",
    "model.add(CuDNNLSTM(num_lstm_cells,kernel_initializer='glorot_normal',return_sequences=False, name='2_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='3_dropout_layer'))\n",
    "\n",
    "model.add(Dense(int(num_lstm_cells/2),kernel_initializer='glorot_normal',\n",
    "                bias_initializer=initializers.Constant(value=0.1), name='dense_layer'))\n",
    "\n",
    "model.add(Dense(classes,kernel_initializer='glorot_normal',\n",
    "                bias_initializer=initializers.Constant(value=0.1),activation='softmax', name='softmax_layer'))\n",
    "\n",
    "opt = optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_conv_layer: input shape: (None, 24, 113, 1) output shape: (None, 20, 113, 64)\n",
      "2_conv_layer: input shape: (None, 20, 113, 64) output shape: (None, 16, 113, 64)\n",
      "3_conv_layer: input shape: (None, 16, 113, 64) output shape: (None, 12, 113, 64)\n",
      "4_conv_layer: input shape: (None, 12, 113, 64) output shape: (None, 8, 113, 64)\n",
      "reshape_3: input shape: (None, 8, 113, 64) output shape: (None, 8, 7232)\n",
      "1_lstm_layer: input shape: (None, 8, 7232) output shape: (None, 8, 128)\n",
      "2_dropout_layer: input shape: (None, 8, 128) output shape: (None, 8, 128)\n",
      "2_lstm_layer: input shape: (None, 8, 128) output shape: (None, 128)\n",
      "3_dropout_layer: input shape: (None, 128) output shape: (None, 128)\n",
      "dense_layer: input shape: (None, 128) output shape: (None, 64)\n",
      "softmax_layer: input shape: (None, 64) output shape: (None, 18)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(str(layer.name) + ': input shape: ' + str(layer.input_shape) + ' output shape: ' + str(layer.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41416 samples, validate on 5078 samples\n",
      "Epoch 1/50\n",
      "41416/41416 [==============================] - 50s 1ms/step - loss: 1.0712 - acc: 0.7158 - val_loss: 0.6360 - val_acc: 0.8125\n",
      "Epoch 2/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.5836 - acc: 0.7970 - val_loss: 0.5562 - val_acc: 0.8291\n",
      "Epoch 3/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.4796 - acc: 0.8291 - val_loss: 0.5296 - val_acc: 0.8529\n",
      "Epoch 4/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.4287 - acc: 0.8466 - val_loss: 0.5174 - val_acc: 0.8527\n",
      "Epoch 5/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.3850 - acc: 0.8665 - val_loss: 0.4697 - val_acc: 0.8686\n",
      "Epoch 6/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.3479 - acc: 0.8805 - val_loss: 0.5123 - val_acc: 0.8600\n",
      "Epoch 7/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.3231 - acc: 0.8895 - val_loss: 0.4714 - val_acc: 0.8755\n",
      "Epoch 8/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.2934 - acc: 0.9012 - val_loss: 0.5461 - val_acc: 0.8740\n",
      "Epoch 9/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.2718 - acc: 0.9098 - val_loss: 0.5237 - val_acc: 0.8643\n",
      "Epoch 10/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.2520 - acc: 0.9165 - val_loss: 0.4957 - val_acc: 0.8775\n",
      "Epoch 11/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.2312 - acc: 0.9251 - val_loss: 0.6029 - val_acc: 0.8744\n",
      "Epoch 12/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.2167 - acc: 0.9291 - val_loss: 0.4851 - val_acc: 0.8862\n",
      "Epoch 13/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.2055 - acc: 0.9331 - val_loss: 0.4976 - val_acc: 0.8820\n",
      "Epoch 14/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.1933 - acc: 0.9392 - val_loss: 0.4658 - val_acc: 0.8937\n",
      "Epoch 15/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.1827 - acc: 0.9439 - val_loss: 0.6256 - val_acc: 0.8899\n",
      "Epoch 16/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.1736 - acc: 0.9445 - val_loss: 0.4908 - val_acc: 0.8903\n",
      "Epoch 17/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.1651 - acc: 0.9477 - val_loss: 0.7943 - val_acc: 0.8685\n",
      "Epoch 18/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1536 - acc: 0.9505 - val_loss: 0.5205 - val_acc: 0.8864\n",
      "Epoch 19/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1458 - acc: 0.9547 - val_loss: 0.5677 - val_acc: 0.8874\n",
      "Epoch 20/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1395 - acc: 0.9566 - val_loss: 0.6031 - val_acc: 0.8917\n",
      "Epoch 21/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1355 - acc: 0.9580 - val_loss: 0.6483 - val_acc: 0.8893\n",
      "Epoch 22/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1305 - acc: 0.9602 - val_loss: 0.5596 - val_acc: 0.8846\n",
      "Epoch 23/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1252 - acc: 0.9605 - val_loss: 0.5925 - val_acc: 0.8919\n",
      "Epoch 24/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1183 - acc: 0.9635 - val_loss: 0.6401 - val_acc: 0.8899\n",
      "Epoch 25/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1113 - acc: 0.9651 - val_loss: 0.6357 - val_acc: 0.8948\n",
      "Epoch 26/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1099 - acc: 0.9662 - val_loss: 0.6279 - val_acc: 0.8931\n",
      "Epoch 27/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.1031 - acc: 0.9681 - val_loss: 0.6485 - val_acc: 0.8901\n",
      "Epoch 28/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.1025 - acc: 0.9683 - val_loss: 0.6646 - val_acc: 0.8919\n",
      "Epoch 29/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0946 - acc: 0.9707 - val_loss: 0.7658 - val_acc: 0.8836\n",
      "Epoch 30/50\n",
      "41416/41416 [==============================] - 50s 1ms/step - loss: 0.0928 - acc: 0.9719 - val_loss: 0.6508 - val_acc: 0.8858\n",
      "Epoch 31/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0895 - acc: 0.9731 - val_loss: 0.6065 - val_acc: 0.8964\n",
      "Epoch 32/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0920 - acc: 0.9724 - val_loss: 0.6802 - val_acc: 0.8850\n",
      "Epoch 33/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0867 - acc: 0.9735 - val_loss: 0.6357 - val_acc: 0.8972\n",
      "Epoch 34/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0801 - acc: 0.9753 - val_loss: 0.7205 - val_acc: 0.8895\n",
      "Epoch 35/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0805 - acc: 0.9764 - val_loss: 0.7397 - val_acc: 0.8911\n",
      "Epoch 36/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0797 - acc: 0.9764 - val_loss: 0.7268 - val_acc: 0.8941\n",
      "Epoch 37/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0774 - acc: 0.9762 - val_loss: 0.7233 - val_acc: 0.8805\n",
      "Epoch 38/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0777 - acc: 0.9770 - val_loss: 0.6721 - val_acc: 0.8909\n",
      "Epoch 39/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0723 - acc: 0.9791 - val_loss: 0.7547 - val_acc: 0.8929\n",
      "Epoch 40/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0690 - acc: 0.9799 - val_loss: 0.8268 - val_acc: 0.8811\n",
      "Epoch 41/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0641 - acc: 0.9806 - val_loss: 0.7781 - val_acc: 0.8854\n",
      "Epoch 42/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0669 - acc: 0.9803 - val_loss: 0.7932 - val_acc: 0.8921\n",
      "Epoch 43/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0652 - acc: 0.9810 - val_loss: 0.7823 - val_acc: 0.8941\n",
      "Epoch 44/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0612 - acc: 0.9819 - val_loss: 0.7777 - val_acc: 0.8964\n",
      "Epoch 45/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0631 - acc: 0.9821 - val_loss: 0.9749 - val_acc: 0.8854\n",
      "Epoch 46/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0611 - acc: 0.9832 - val_loss: 0.8413 - val_acc: 0.8941\n",
      "Epoch 47/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0622 - acc: 0.9831 - val_loss: 0.7122 - val_acc: 0.8931\n",
      "Epoch 48/50\n",
      "41416/41416 [==============================] - 48s 1ms/step - loss: 0.0574 - acc: 0.9833 - val_loss: 0.9087 - val_acc: 0.8885\n",
      "Epoch 49/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0564 - acc: 0.9835 - val_loss: 0.8337 - val_acc: 0.8933\n",
      "Epoch 50/50\n",
      "41416/41416 [==============================] - 49s 1ms/step - loss: 0.0596 - acc: 0.9836 - val_loss: 0.7811 - val_acc: 0.8956\n",
      "Calculating score.. \n",
      "9894/9894 [==============================] - 5s 552us/step\n",
      "[0.74172882173883492, 0.88791186577723868]\n"
     ]
    }
   ],
   "source": [
    "batchSize = 100\n",
    "train_epoches = 50\n",
    "\n",
    "model.fit(reshaped_train,train_labels,validation_data=(reshaped_val,val_labels),epochs=train_epoches,batch_size=batchSize,verbose=1)\n",
    "\n",
    "print('Calculating score.. ')\n",
    "score = model.evaluate(reshaped_test,test_labels,verbose=1)\n",
    "print(score)\n",
    "model.save('taskB2_all_Subjects_CNN_LSTM_our_elaboration_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46494 samples, validate on 9894 samples\n",
      "Epoch 1/20\n",
      "46494/46494 [==============================] - 57s 1ms/step - loss: 0.1188 - acc: 0.9725 - val_loss: 0.4993 - val_acc: 0.8899\n",
      "Epoch 2/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0981 - acc: 0.9741 - val_loss: 0.4215 - val_acc: 0.9061\n",
      "Epoch 3/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0894 - acc: 0.9763 - val_loss: 0.4779 - val_acc: 0.9002\n",
      "Epoch 4/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0814 - acc: 0.9776 - val_loss: 0.4861 - val_acc: 0.9042\n",
      "Epoch 5/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0779 - acc: 0.9786 - val_loss: 0.5358 - val_acc: 0.9038\n",
      "Epoch 6/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0737 - acc: 0.9792 - val_loss: 0.4544 - val_acc: 0.9066\n",
      "Epoch 7/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0673 - acc: 0.9816 - val_loss: 0.5327 - val_acc: 0.8968\n",
      "Epoch 8/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0649 - acc: 0.9819 - val_loss: 0.5424 - val_acc: 0.9090\n",
      "Epoch 9/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0590 - acc: 0.9833 - val_loss: 0.5306 - val_acc: 0.9039\n",
      "Epoch 10/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0631 - acc: 0.9830 - val_loss: 0.5455 - val_acc: 0.9054\n",
      "Epoch 11/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0574 - acc: 0.9834 - val_loss: 0.5539 - val_acc: 0.9011\n",
      "Epoch 12/20\n",
      "46494/46494 [==============================] - 57s 1ms/step - loss: 0.0575 - acc: 0.9837 - val_loss: 0.5814 - val_acc: 0.9056\n",
      "Epoch 13/20\n",
      "46494/46494 [==============================] - 57s 1ms/step - loss: 0.0538 - acc: 0.9844 - val_loss: 0.6105 - val_acc: 0.9046\n",
      "Epoch 14/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0530 - acc: 0.9857 - val_loss: 0.5656 - val_acc: 0.9039\n",
      "Epoch 15/20\n",
      "46494/46494 [==============================] - 57s 1ms/step - loss: 0.0508 - acc: 0.9865 - val_loss: 0.6282 - val_acc: 0.9024\n",
      "Epoch 16/20\n",
      "46494/46494 [==============================] - 55s 1ms/step - loss: 0.0520 - acc: 0.9855 - val_loss: 0.5994 - val_acc: 0.9034\n",
      "Epoch 17/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0498 - acc: 0.9865 - val_loss: 0.6566 - val_acc: 0.9019\n",
      "Epoch 18/20\n",
      "46494/46494 [==============================] - 56s 1ms/step - loss: 0.0465 - acc: 0.9876 - val_loss: 0.6197 - val_acc: 0.8985\n",
      "Epoch 19/20\n",
      "46494/46494 [==============================] - 55s 1ms/step - loss: 0.0558 - acc: 0.9868 - val_loss: 0.6682 - val_acc: 0.9060\n",
      "Epoch 20/20\n",
      "46494/46494 [==============================] - 55s 1ms/step - loss: 0.0445 - acc: 0.9880 - val_loss: 0.6687 - val_acc: 0.8979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c9ed40f60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoches = 20\n",
    "all_train = np.concatenate((reshaped_train, reshaped_val))\n",
    "all_labels = np.concatenate((train_labels, val_labels))\n",
    "model.fit(all_train,all_labels,validation_data=(reshaped_test,test_labels),epochs=train_epoches,batch_size=batchSize,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(reshaped_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy is 0.8979179300586214\n",
      "0 0.832524762482 0.946513446844\n",
      "1 0.0058621386699 0.571428571429\n",
      "2 0.00960177885587 0.887640449438\n",
      "3 0.00606428138266 0.625\n",
      "4 0.00838892257934 0.88\n",
      "5 0.0230442692541 0.661654135338\n",
      "6 0.0161714170204 0.747404844291\n",
      "7 0.0101071356378 0.616113744076\n",
      "8 0.00778249444108 0.51497005988\n",
      "9 0.00394178289873 0.567567567568\n",
      "10 0.00424499696786 0.394736842105\n",
      "11 0.0040428542551 0.523076923077\n",
      "12 0.00262785526582 0.52\n",
      "13 0.0067717808773 0.651162790698\n",
      "14 0.00616535273903 0.64406779661\n",
      "15 0.0100060642814 0.533333333333\n",
      "16 0.0320396199717 0.615384615385\n",
      "17 0.0106124924196 0.573170731707\n",
      "The weigths sum is 1.0\n",
      "The computed f1-score is 0.8955204164504978\n",
      "The f1-score with sklearn function is 0.8955204164504977\n"
     ]
    }
   ],
   "source": [
    "# F1-score measure\n",
    "from sklearn.metrics import f1_score\n",
    "num_classes = 18\n",
    "class_predictions = []\n",
    "class_true = []\n",
    "tot_labels = 0.0\n",
    "count = 0.0\n",
    "for pair in zip(predictions, test_labels):\n",
    "    class_predictions.append(np.argmax(pair[0]))\n",
    "    class_true.append(np.argmax(pair[1]))\n",
    "    if np.argmax(pair[0]) == np.argmax(pair[1]):\n",
    "        count += 1.0\n",
    "    tot_labels += 1.0\n",
    "    \n",
    "print('Standard accuracy is ' + str(count/tot_labels))    \n",
    "\n",
    "unique, counts = np.unique(class_true, return_counts=True)\n",
    "counted_labels = dict(zip(unique, counts))\n",
    "f1_scores = f1_score(class_predictions, class_true, average=None)\n",
    "\n",
    "tot_f1_score = 0.0\n",
    "weights_sum = 0.0\n",
    "for i in range(num_classes):\n",
    "    labels_class_i = counted_labels[i]\n",
    "    weight_i = labels_class_i / tot_labels\n",
    "    weights_sum += weight_i\n",
    "    tot_f1_score += f1_scores[i]*weight_i\n",
    "    print(str(i) + ' ' + str(weight_i) + ' ' + str(f1_scores[i]))\n",
    "\n",
    "    \n",
    "print('The weigths sum is ' + str(weights_sum))\n",
    "print('The computed f1-score is {}'.format(tot_f1_score))\n",
    "print('The f1-score with sklearn function is {}'.format(f1_score(class_true, class_predictions, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv('preds_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(testY)\n",
    "true_df.to_csv('true_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
