{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as cp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Conv2D, LSTM, CuDNNLSTM, Flatten, Dropout, Input, TimeDistributed, Reshape\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\"shapes: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "    \n",
    "    print('Dataset loaded successfully')\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slidingWindow(sequence, labels, winSize, step, noNull):\n",
    "\n",
    "    # Verify the inputs\n",
    "    try: it = iter(sequence)\n",
    "    except TypeError:\n",
    "        raise Exception(\"**ERROR** sequence must be iterable.\")\n",
    "    if not ((type(winSize) == type(0)) and (type(step) == type(0))):\n",
    "        raise Exception(\"**ERROR** type(winSize) and type(step) must be int.\")\n",
    "    if step > winSize:\n",
    "        raise Exception(\"**ERROR** step must not be larger than winSize.\")\n",
    "    if winSize > len(sequence):\n",
    "        raise Exception(\"**ERROR** winSize must not be larger than sequence length.\")\n",
    " \n",
    "    # number of chunks\n",
    "    numOfChunks = ((len(sequence)-winSize)//step)+1\n",
    " \n",
    "    # Do the work\n",
    "    for i in range(0,numOfChunks*step,step):\n",
    "        segment = sequence[i:i+winSize]\n",
    "        seg_labels = labels[i:i+winSize]\n",
    "        if noNull:\n",
    "            if seg_labels[-1] != 0:\n",
    "                yield segment, seg_labels\n",
    "        else:\n",
    "            yield segment, seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_data(X_train, y_train, X_test, y_test, winSize, step, noNull=False):\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_test) == len(y_test)\n",
    "    # obtain chunks of data\n",
    "    train_chunks = slidingWindow(X_train, y_train , winSize, step, noNull)\n",
    "    test_chunks = slidingWindow(X_test, y_test, winSize, step, noNull)\n",
    "    \n",
    "    # segment the data\n",
    "    train_segments = []\n",
    "    train_labels = []\n",
    "    for chunk in train_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        train_segments.append(data)\n",
    "        train_labels.append(labels[-1])\n",
    "    \n",
    "    test_segments = []\n",
    "    test_labels = []\n",
    "    for chunk in test_chunks:\n",
    "        data = chunk[0]\n",
    "        labels = chunk[1]\n",
    "        test_segments.append(data)\n",
    "        test_labels.append(labels[-1])\n",
    "        \n",
    "    return np.array(train_segments), np.array(train_labels), np.array(test_segments), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: train (557963, 113), test (118750, 113)\n",
      "Dataset loaded successfully\n"
     ]
    }
   ],
   "source": [
    "num_sensors = 113 # number of sensor channels\n",
    "num_classes = 18 # number of classes \n",
    "window_size = 24 # window size\n",
    "step_size = 12 # half of the sliding window\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_dataset('oppChallenge_gestures.data')\n",
    "\n",
    "train_segments, train_labels, test_segments, test_labels = segment_data(X_train, y_train, X_test, y_test,\n",
    "                                                                        window_size, step_size)\n",
    "encoder = OneHotEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels.reshape(-1,1)).toarray()\n",
    "test_labels = encoder.transform(test_labels.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_segments = train_segments.reshape((-1,window_size, num_sensors,1))\n",
    "test_segments = test_segments.reshape((-1,window_size,num_sensors,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "size_of_kernel = (5,1)\n",
    "kernel_strides = 1\n",
    "num_filters = 64\n",
    "num_lstm_cells = 128\n",
    "dropout_prob = 0.5\n",
    "inputshape = (window_size, num_sensors, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu', input_shape=inputshape, name='1_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu', name='2_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu', name='3_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(num_filters, kernel_size=size_of_kernel, strides=kernel_strides,\n",
    "                 activation='relu', name='4_conv_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Reshape((8, num_filters*num_sensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tommy Azzino\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Tommy Azzino\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.add(CuDNNLSTM(num_lstm_cells, return_sequences=True, name='1_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='2_dropout_layer'))\n",
    "\n",
    "model.add(CuDNNLSTM(num_lstm_cells, return_sequences=False, name='2_lstm_layer'))\n",
    "\n",
    "model.add(Dropout(dropout_prob, name='3_dropout_layer'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax', name='softmax_layer'))\n",
    "\n",
    "rms = optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_conv_layer: input shape: (None, 24, 113, 1) output shape: (None, 20, 113, 64)\n",
      "2_conv_layer: input shape: (None, 20, 113, 64) output shape: (None, 16, 113, 64)\n",
      "3_conv_layer: input shape: (None, 16, 113, 64) output shape: (None, 12, 113, 64)\n",
      "4_conv_layer: input shape: (None, 12, 113, 64) output shape: (None, 8, 113, 64)\n",
      "reshape_1: input shape: (None, 8, 113, 64) output shape: (None, 8, 7232)\n",
      "1_lstm_layer: input shape: (None, 8, 7232) output shape: (None, 8, 128)\n",
      "2_dropout_layer: input shape: (None, 8, 128) output shape: (None, 8, 128)\n",
      "2_lstm_layer: input shape: (None, 8, 128) output shape: (None, 128)\n",
      "3_dropout_layer: input shape: (None, 128) output shape: (None, 128)\n",
      "softmax_layer: input shape: (None, 128) output shape: (None, 18)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(str(layer.name) + ': input shape: ' + str(layer.input_shape) + ' output shape: ' + str(layer.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "1_conv_layer (Conv2D)        (None, 20, 113, 64)       384       \n",
      "_________________________________________________________________\n",
      "2_conv_layer (Conv2D)        (None, 16, 113, 64)       20544     \n",
      "_________________________________________________________________\n",
      "3_conv_layer (Conv2D)        (None, 12, 113, 64)       20544     \n",
      "_________________________________________________________________\n",
      "4_conv_layer (Conv2D)        (None, 8, 113, 64)        20544     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 7232)           0         \n",
      "_________________________________________________________________\n",
      "1_lstm_layer (CuDNNLSTM)     (None, 8, 128)            3769344   \n",
      "_________________________________________________________________\n",
      "2_dropout_layer (Dropout)    (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "2_lstm_layer (CuDNNLSTM)     (None, 128)               132096    \n",
      "_________________________________________________________________\n",
      "3_dropout_layer (Dropout)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "softmax_layer (Dense)        (None, 18)                2322      \n",
      "=================================================================\n",
      "Total params: 3,965,778\n",
      "Trainable params: 3,965,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46495 samples, validate on 9894 samples\n",
      "Epoch 1/50\n",
      "46495/46495 [==============================] - 61s 1ms/step - loss: 1.0147 - acc: 0.7414 - val_loss: 0.4515 - val_acc: 0.8573\n",
      "Epoch 2/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.5355 - acc: 0.8201 - val_loss: 0.4024 - val_acc: 0.8721\n",
      "Epoch 3/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.4442 - acc: 0.8466 - val_loss: 0.3622 - val_acc: 0.8876\n",
      "Epoch 4/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.3911 - acc: 0.8632 - val_loss: 0.3303 - val_acc: 0.8890\n",
      "Epoch 5/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.3551 - acc: 0.8754 - val_loss: 0.3679 - val_acc: 0.8892\n",
      "Epoch 6/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.3242 - acc: 0.8881 - val_loss: 0.3372 - val_acc: 0.8947\n",
      "Epoch 7/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.2930 - acc: 0.8992 - val_loss: 0.3612 - val_acc: 0.8870\n",
      "Epoch 8/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.2760 - acc: 0.9064 - val_loss: 0.3348 - val_acc: 0.8972\n",
      "Epoch 9/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.2521 - acc: 0.9158 - val_loss: 0.3580 - val_acc: 0.8902\n",
      "Epoch 10/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.2356 - acc: 0.9214 - val_loss: 0.3515 - val_acc: 0.9001\n",
      "Epoch 11/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.2205 - acc: 0.9260 - val_loss: 0.3603 - val_acc: 0.8962\n",
      "Epoch 12/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.2064 - acc: 0.9313 - val_loss: 0.3616 - val_acc: 0.8906\n",
      "Epoch 13/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1977 - acc: 0.9357 - val_loss: 0.3774 - val_acc: 0.8994\n",
      "Epoch 14/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1830 - acc: 0.9399 - val_loss: 0.3739 - val_acc: 0.8984\n",
      "Epoch 15/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1744 - acc: 0.9447 - val_loss: 0.4007 - val_acc: 0.8951\n",
      "Epoch 16/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1671 - acc: 0.9464 - val_loss: 0.4025 - val_acc: 0.9012\n",
      "Epoch 17/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1580 - acc: 0.9499 - val_loss: 0.4270 - val_acc: 0.8991\n",
      "Epoch 18/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1511 - acc: 0.9530 - val_loss: 0.4814 - val_acc: 0.8953\n",
      "Epoch 19/50\n",
      "46495/46495 [==============================] - 60s 1ms/step - loss: 0.1434 - acc: 0.9543 - val_loss: 0.4399 - val_acc: 0.9018\n",
      "Epoch 20/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1393 - acc: 0.9571 - val_loss: 0.4478 - val_acc: 0.9041\n",
      "Epoch 21/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.1319 - acc: 0.9577 - val_loss: 0.4530 - val_acc: 0.8994\n",
      "Epoch 22/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.1365 - acc: 0.9583 - val_loss: 0.4574 - val_acc: 0.9057\n",
      "Epoch 23/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1249 - acc: 0.9609 - val_loss: 0.4777 - val_acc: 0.9034\n",
      "Epoch 24/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.1168 - acc: 0.9633 - val_loss: 0.5268 - val_acc: 0.9005\n",
      "Epoch 25/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1138 - acc: 0.9646 - val_loss: 0.4677 - val_acc: 0.9032\n",
      "Epoch 26/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.1130 - acc: 0.9650 - val_loss: 0.4951 - val_acc: 0.8945\n",
      "Epoch 27/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.1109 - acc: 0.9660 - val_loss: 0.5097 - val_acc: 0.9026\n",
      "Epoch 28/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.1085 - acc: 0.9675 - val_loss: 0.4940 - val_acc: 0.9011\n",
      "Epoch 29/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.1022 - acc: 0.9690 - val_loss: 0.5207 - val_acc: 0.9019\n",
      "Epoch 30/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.1015 - acc: 0.9691 - val_loss: 0.5057 - val_acc: 0.9021\n",
      "Epoch 31/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0968 - acc: 0.9702 - val_loss: 0.5424 - val_acc: 0.9049\n",
      "Epoch 32/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0927 - acc: 0.9718 - val_loss: 0.5819 - val_acc: 0.8983\n",
      "Epoch 33/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0903 - acc: 0.9730 - val_loss: 0.5710 - val_acc: 0.9020\n",
      "Epoch 34/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0883 - acc: 0.9733 - val_loss: 0.6199 - val_acc: 0.9060\n",
      "Epoch 35/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.0888 - acc: 0.9742 - val_loss: 0.6164 - val_acc: 0.8967\n",
      "Epoch 36/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0833 - acc: 0.9749 - val_loss: 0.5239 - val_acc: 0.9048\n",
      "Epoch 37/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0841 - acc: 0.9749 - val_loss: 0.5861 - val_acc: 0.8994\n",
      "Epoch 38/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.0795 - acc: 0.9765 - val_loss: 0.5824 - val_acc: 0.9036\n",
      "Epoch 39/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0771 - acc: 0.9775 - val_loss: 0.6086 - val_acc: 0.9000\n",
      "Epoch 40/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0782 - acc: 0.9771 - val_loss: 0.5700 - val_acc: 0.8990\n",
      "Epoch 41/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0769 - acc: 0.9776 - val_loss: 0.6219 - val_acc: 0.8990\n",
      "Epoch 42/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.0753 - acc: 0.9777 - val_loss: 0.7078 - val_acc: 0.8944\n",
      "Epoch 43/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.0784 - acc: 0.9785 - val_loss: 0.6687 - val_acc: 0.9022\n",
      "Epoch 44/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0761 - acc: 0.9787 - val_loss: 0.6284 - val_acc: 0.8997\n",
      "Epoch 45/50\n",
      "46495/46495 [==============================] - 55s 1ms/step - loss: 0.0761 - acc: 0.9786 - val_loss: 0.6427 - val_acc: 0.9025\n",
      "Epoch 46/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0736 - acc: 0.9796 - val_loss: 0.6356 - val_acc: 0.9022\n",
      "Epoch 47/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0654 - acc: 0.9813 - val_loss: 0.6979 - val_acc: 0.9053\n",
      "Epoch 48/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0737 - acc: 0.9802 - val_loss: 0.6518 - val_acc: 0.9015\n",
      "Epoch 49/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0688 - acc: 0.9803 - val_loss: 0.6609 - val_acc: 0.8933\n",
      "Epoch 50/50\n",
      "46495/46495 [==============================] - 54s 1ms/step - loss: 0.0635 - acc: 0.9817 - val_loss: 0.7752 - val_acc: 0.8928\n",
      "Calculating score.. \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'reshaped_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4a08a1e60fbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calculating score.. '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_segments_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taskB2_all_Subjects_CNN_LSTM_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reshaped_test' is not defined"
     ]
    }
   ],
   "source": [
    "batchSize = 100\n",
    "train_epoches = 50\n",
    "model.fit(train_segments,train_labels,validation_data=(test_segments,test_labels),epochs=train_epoches,batch_size=batchSize,verbose=1)\n",
    "\n",
    "print('Calculating score.. ')\n",
    "score = model.evaluate(test_segments,test_labels,verbose=1)\n",
    "print(score)\n",
    "model.save('taskB2_all_Subjects_CNN_LSTM_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy is 0.8927632908833637\n",
      "The computed f1-score is 0.8945253356596347\n",
      "The f1-score with sklearn function is 0.8945253356596349\n"
     ]
    }
   ],
   "source": [
    "# F1-score measure\n",
    "from sklearn.metrics import f1_score\n",
    "num_classes = 18\n",
    "class_predictions = []\n",
    "class_true = []\n",
    "tot_labels = 0.0\n",
    "count = 0.0\n",
    "for pair in zip(predictions, test_labels):\n",
    "    class_predictions.append(np.argmax(pair[0]))\n",
    "    class_true.append(np.argmax(pair[1]))\n",
    "    if np.argmax(pair[0]) == np.argmax(pair[1]):\n",
    "        count += 1.0\n",
    "    tot_labels += 1.0\n",
    "    \n",
    "print('Standard accuracy is ' + str(count/tot_labels))    \n",
    "\n",
    "unique, counts = np.unique(class_true, return_counts=True)\n",
    "counted_labels = dict(zip(unique, counts))\n",
    "f1_scores = f1_score(class_predictions, class_true, average=None)\n",
    "\n",
    "tot_f1_score = 0.0\n",
    "weights_sum = 0.0\n",
    "for i in range(num_classes):\n",
    "    labels_class_i = counted_labels[i]\n",
    "    weight_i = labels_class_i / tot_labels\n",
    "    weights_sum += weight_i\n",
    "    tot_f1_score += f1_scores[i]*weight_i\n",
    "    \n",
    "print('The computed f1-score is {}'.format(tot_f1_score))\n",
    "print('The f1-score with sklearn function is {}'.format(f1_score(class_true, class_predictions, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv('preds_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(testY)\n",
    "true_df.to_csv('true_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
