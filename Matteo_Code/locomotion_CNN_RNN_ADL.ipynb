{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, LSTM, CuDNNLSTM, Flatten, Dropout\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainerHelper():\n",
    "    \n",
    "    def __init__(self, data, labels, win_size, num_sensor_data, num_classes):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.win_size = win_size\n",
    "        self.sensor_data = num_sensor_data\n",
    "        self.num_classes = num_classes\n",
    "        self.data_length = self.data.shape[0]\n",
    "        print(self.data_length)\n",
    "        self.start = 0\n",
    "        \n",
    "    def windows(self):\n",
    " \n",
    "        while self.start + self.win_size < self.data_length:\n",
    "            yield int(self.start), int(self.start + self.win_size)\n",
    "            self.start += (self.win_size/2)\n",
    "    \n",
    "    def segment_data(self,lenght):\n",
    "        self.start = 0\n",
    "        segments = np.empty((0, self.win_size, lenght))\n",
    "        labels= np.empty((0, self.num_classes))\n",
    "        for (start, end) in self.windows():\n",
    "            x = np.zeros((1, self.win_size,lenght))\n",
    "            x[0,:] = self.data[start:end,:]\n",
    "            label = self.labels[start:end,:]\n",
    "            if(x.shape[1] == self.win_size):\n",
    "                segments = np.vstack([segments,x])\n",
    "                lb = np.zeros((1, self.num_classes))\n",
    "                lb[0,:] = label[-1]\n",
    "                labels = np.vstack([labels,lb])\n",
    "        return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= pd.read_csv(\"ADL1Opportunity_locomotion.csv\",header=None)\n",
    "data2= pd.read_csv(\"ADL2Opportunity_locomotion.csv\",header=None)\n",
    "data3= pd.read_csv(\"ADL3Opportunity_locomotion.csv\",header=None)\n",
    "data4= pd.read_csv(\"ADL4Opportunity_locomotion.csv\",header=None)\n",
    "data5= pd.read_csv(\"ADL5Opportunity_locomotion.csv\",header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def prepare_data(data):\n",
    "    encoder = OneHotEncoder()\n",
    "    print('Processing..')\n",
    "    one_hot_labels = encoder.fit_transform(data['labels'].values.reshape(-1,1)).toarray()\n",
    "    one_hot_labels.shape\n",
    "    scaler = MinMaxScaler()\n",
    "    data.drop(['labels'], 1, inplace=True)\n",
    "    data.shape\n",
    "    data = scaler.fit_transform(data)\n",
    "    trainer_helper = trainerHelper(data, one_hot_labels, 15, data.shape[1]-1, 5)\n",
    "    segments, labels = trainer_helper.segment_data(data.shape[1])\n",
    "\n",
    "    return segments,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing..\n",
      "51088\n",
      "Processing..\n",
      "32223\n",
      "Processing..\n",
      "33274\n",
      "Processing..\n",
      "32955\n",
      "Processing..\n",
      "32955\n"
     ]
    }
   ],
   "source": [
    "train_list=[];\n",
    "test_list=[];\n",
    "data1.rename(columns ={data1.shape[1]-1: 'labels'}, inplace =True)\n",
    "[segments,labels1]=prepare_data(data1)\n",
    "train_list.append([segments,labels1])\n",
    "\n",
    "data2.rename(columns ={data2.shape[1]-1: 'labels'}, inplace =True)\n",
    "[segments,labels2]=prepare_data(data2)\n",
    "train_list.append([segments,labels2])\n",
    "\n",
    "\n",
    "data3.rename(columns ={data3.shape[1]-1: 'labels'}, inplace =True)\n",
    "[segments,labels3]=prepare_data(data3)\n",
    "train_list.append([segments,labels3])\n",
    "\n",
    "data4.rename(columns ={data4.shape[1]-1: 'labels'}, inplace =True)\n",
    "[segments,labels4]=prepare_data(data4)\n",
    "test_list.append([segments,labels4])\n",
    "\n",
    "data5.rename(columns ={data5.shape[1]-1: 'labels'}, inplace =True)\n",
    "[segments,labels5]=prepare_data(data5)\n",
    "test_list.append([segments,labels5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COrrect reshape \n",
    "\n",
    "#Train\n",
    "for train_instance in train_list:\n",
    "    train_instance[0]=train_instance[0].transpose(0,2,1)\n",
    "#TEst\n",
    "for test_instance in test_list:\n",
    "    test_instance[0]=test_instance[0].transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model= Sequential()\n",
    "\n",
    "\n",
    "win_size = 15\n",
    "classes = 5\n",
    "num_sensors = data1.shape[1]\n",
    "kernel_height = 5\n",
    "inputshape = (num_sensors, win_size)\n",
    "trainSplitRatio=0.8;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu',\n",
    "                 input_shape=inputshape))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "adam = optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d_1\n",
      "conv1d_2\n",
      "conv1d_3\n",
      "conv1d_4\n",
      "dropout_1\n",
      "lstm_1\n",
      "dropout_2\n",
      "lstm_2\n",
      "dropout_3\n",
      "dense_1\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15540, 113, 15)\n",
      "(15540, 5)\n",
      "Epoch 1/1\n",
      "15540/15540 [==============================] - 133s 9ms/step - loss: 1.4555 - acc: 0.3609\n",
      "8784/8784 [==============================] - 27s 3ms/step\n",
      "[1.4638833248332985, 0.34631147540983609]\n"
     ]
    }
   ],
   "source": [
    "batchSize = 100\n",
    "# TRAIN\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "for train_instance in train_list:\n",
    "    trainX.append(train_instance[0])\n",
    "    trainY.append(train_instance[1])\n",
    "\n",
    "trainX=np.concatenate(trainX,axis=0)\n",
    "trainY=np.concatenate(trainY,axis=0)    \n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "#TEST\n",
    "\n",
    "testX=[]\n",
    "testY=[]\n",
    "for test_instance in test_list:\n",
    "    testX.append(test_instance[0])\n",
    "    testY.append(test_instance[1])\n",
    "\n",
    "testX=np.concatenate(testX,axis=0)\n",
    "testY=np.concatenate(testY,axis=0) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(trainX,trainY,epochs=1,batch_size=batchSize,verbose=1)\n",
    "print('Calculating score.. ')\n",
    "score = model.evaluate(testX,testY,verbose=1)\n",
    "print(score)\n",
    "model.save('CIP_ADL_CNN4_LSTM2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3185336976320583\n"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "den = 0.0\n",
    "for pair in zip(predictions, testY):\n",
    "    if np.argmax(pair[0]) == np.argmax(pair[1]):\n",
    "        count += 1.0\n",
    "    den += 1.0\n",
    "\n",
    "print(count / den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv('preds_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(testY)\n",
    "true_df.to_csv('true_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
