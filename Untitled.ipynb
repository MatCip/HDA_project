{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, LSTM, CuDNNLSTM, Flatten, Dropout\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"drill1Opportunity.csv\",header=None)\n",
    "data.rename(columns ={110: 'labels'}, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54915, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "one_hot_labels = encoder.fit_transform(data['labels'].values.reshape(-1,1)).toarray()\n",
    "one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data.drop(['labels'], 1, inplace=True)\n",
    "data.shape\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class trainerHelper():\n",
    "    \n",
    "    def __init__(self, data, labels, win_size, num_sensor_data, num_classes):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.win_size = win_size\n",
    "        self.sensor_data = num_sensor_data\n",
    "        self.num_classes = num_classes\n",
    "        self.data_length = self.data.shape[0]\n",
    "        print(self.data_length)\n",
    "        self.start = 0\n",
    "        \n",
    "    def windows(self):\n",
    " \n",
    "        while self.start + self.win_size < self.data_length:\n",
    "            yield int(self.start), int(self.start + self.win_size)\n",
    "            self.start += (self.win_size/2)\n",
    "    \n",
    "    def segment_data(self):\n",
    "        self.start = 0\n",
    "        segments = np.empty((0, self.win_size, 110))\n",
    "        labels= np.empty((0, self.num_classes))\n",
    "        for (start, end) in self.windows():\n",
    "            x = np.zeros((1, self.win_size, 110))\n",
    "            x[0,:] = self.data[start:end,:]\n",
    "            label = self.labels[start:end,:]\n",
    "            if(x.shape[1] == self.win_size):\n",
    "                segments = np.vstack([segments,x])\n",
    "                lb = np.zeros((1, self.num_classes))\n",
    "                lb[0,:] = label[-1]\n",
    "                labels = np.vstack([labels,lb])\n",
    "        return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54915\n"
     ]
    }
   ],
   "source": [
    "trainer_helper = trainerHelper(data, one_hot_labels, 15, 110, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments, labels = trainer_helper.segment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7320, 15, 110)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7320, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot_segments = segments\n",
    "tot_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maybe we need to normalize the data\n",
    "num_rows = segments.shape[1]\n",
    "num_cols = segments.shape[2]\n",
    "trainSplitRatio = 0.8\n",
    "# reshaping segments for network input\n",
    "reshapedSegments = segments.transpose(0,2,1)\n",
    "# splitting segments in training and testing data\n",
    "trainSplit = np.random.rand(len(reshapedSegments)) < trainSplitRatio\n",
    "trainX = reshapedSegments[trainSplit]\n",
    "testX = reshapedSegments[~trainSplit]\n",
    "trainY = labels[trainSplit]\n",
    "testY = labels[~trainSplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5803, 110, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56200975  0.55776977  0.57197371  0.56794573  0.57070172  0.56476574\n",
      "  0.55416578  0.55904176  0.55882976  0.55522578  0.55819377  0.54526182\n",
      "  0.56010176  0.55458978  0.54610982]\n"
     ]
    }
   ],
   "source": [
    "print(reshapedSegments[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential() #permettere di usare la struttura a stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "win_size = 15\n",
    "classes = 18\n",
    "num_sensors = 110\n",
    "kernel_height = 5\n",
    "inputshape = (num_sensors, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu',\n",
    "                 input_shape=(num_sensors,15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv1D(64, kernel_size=kernel_height, strides=1,\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(CuDNNLSTM(128, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(CuDNNLSTM(128, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tommy Azzino\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.RMSprop(lr=0.001, decay=1e-6) \n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d_5\n",
      "conv1d_6\n",
      "conv1d_7\n",
      "conv1d_8\n",
      "dropout_2\n",
      "cu_dnnlstm_1\n",
      "dropout_3\n",
      "cu_dnnlstm_2\n",
      "dropout_4\n",
      "dense_1\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4642 samples, validate on 1161 samples\n",
      "Epoch 1/100\n",
      "4642/4642 [==============================] - 9s 2ms/step - loss: 2.4625 - acc: 0.3501 - val_loss: 2.3604 - val_acc: 0.4126\n",
      "Epoch 2/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 2.4103 - acc: 0.3630 - val_loss: 2.2727 - val_acc: 0.4126\n",
      "Epoch 3/100\n",
      "4642/4642 [==============================] - 2s 457us/step - loss: 2.2840 - acc: 0.3651 - val_loss: 1.9578 - val_acc: 0.3979\n",
      "Epoch 4/100\n",
      "4642/4642 [==============================] - 2s 454us/step - loss: 2.0471 - acc: 0.3785 - val_loss: 1.6888 - val_acc: 0.4470\n",
      "Epoch 5/100\n",
      "4642/4642 [==============================] - 2s 453us/step - loss: 1.8641 - acc: 0.4022 - val_loss: 1.4465 - val_acc: 0.5314\n",
      "Epoch 6/100\n",
      "4642/4642 [==============================] - 2s 454us/step - loss: 1.7453 - acc: 0.4196 - val_loss: 1.5534 - val_acc: 0.4539\n",
      "Epoch 7/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 1.5926 - acc: 0.4582 - val_loss: 1.9199 - val_acc: 0.3945\n",
      "Epoch 8/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 1.5011 - acc: 0.4879 - val_loss: 1.0826 - val_acc: 0.6167\n",
      "Epoch 9/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 1.3929 - acc: 0.5202 - val_loss: 1.1510 - val_acc: 0.5900\n",
      "Epoch 10/100\n",
      "4642/4642 [==============================] - 2s 457us/step - loss: 1.2574 - acc: 0.5679 - val_loss: 0.8769 - val_acc: 0.6985\n",
      "Epoch 11/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 1.1511 - acc: 0.5885 - val_loss: 1.0665 - val_acc: 0.6331\n",
      "Epoch 12/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 1.1029 - acc: 0.6064 - val_loss: 0.9009 - val_acc: 0.6736\n",
      "Epoch 13/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 1.0022 - acc: 0.6290 - val_loss: 1.0746 - val_acc: 0.6072\n",
      "Epoch 14/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 1.0643 - acc: 0.6069 - val_loss: 0.6648 - val_acc: 0.7511\n",
      "Epoch 15/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.8981 - acc: 0.6629 - val_loss: 0.6693 - val_acc: 0.7416\n",
      "Epoch 16/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.8752 - acc: 0.6680 - val_loss: 0.9033 - val_acc: 0.6761\n",
      "Epoch 17/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.8416 - acc: 0.6840 - val_loss: 0.7678 - val_acc: 0.7003\n",
      "Epoch 18/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.7792 - acc: 0.7047 - val_loss: 0.6479 - val_acc: 0.7468\n",
      "Epoch 19/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.7502 - acc: 0.7148 - val_loss: 0.7188 - val_acc: 0.7442\n",
      "Epoch 20/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.7206 - acc: 0.7210 - val_loss: 0.6336 - val_acc: 0.7631\n",
      "Epoch 21/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.7072 - acc: 0.7262 - val_loss: 0.9237 - val_acc: 0.6529\n",
      "Epoch 22/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.6935 - acc: 0.7301 - val_loss: 1.0534 - val_acc: 0.6675\n",
      "Epoch 23/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.6615 - acc: 0.7408 - val_loss: 0.5242 - val_acc: 0.7898\n",
      "Epoch 24/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.6474 - acc: 0.7559 - val_loss: 0.6929 - val_acc: 0.7175\n",
      "Epoch 25/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.6245 - acc: 0.7536 - val_loss: 0.5560 - val_acc: 0.7812\n",
      "Epoch 26/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.6470 - acc: 0.7501 - val_loss: 0.5383 - val_acc: 0.7812\n",
      "Epoch 27/100\n",
      "4642/4642 [==============================] - 2s 463us/step - loss: 0.5960 - acc: 0.7686 - val_loss: 0.6489 - val_acc: 0.7450\n",
      "Epoch 28/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.6007 - acc: 0.7684 - val_loss: 0.6013 - val_acc: 0.7649\n",
      "Epoch 29/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.5596 - acc: 0.7796 - val_loss: 0.5251 - val_acc: 0.7993\n",
      "Epoch 30/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.5599 - acc: 0.7785 - val_loss: 0.6593 - val_acc: 0.7330\n",
      "Epoch 31/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.5459 - acc: 0.7895 - val_loss: 0.8698 - val_acc: 0.7011\n",
      "Epoch 32/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.5219 - acc: 0.7984 - val_loss: 0.4618 - val_acc: 0.8269\n",
      "Epoch 33/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.5162 - acc: 0.8009 - val_loss: 0.5055 - val_acc: 0.7993\n",
      "Epoch 34/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.5068 - acc: 0.8029 - val_loss: 0.4936 - val_acc: 0.8045\n",
      "Epoch 35/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.5018 - acc: 0.8068 - val_loss: 0.4746 - val_acc: 0.7984\n",
      "Epoch 36/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.4845 - acc: 0.8132 - val_loss: 0.4476 - val_acc: 0.8096\n",
      "Epoch 37/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.4755 - acc: 0.8165 - val_loss: 0.6173 - val_acc: 0.7743\n",
      "Epoch 38/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.4774 - acc: 0.8145 - val_loss: 0.5193 - val_acc: 0.7993\n",
      "Epoch 39/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.4407 - acc: 0.8283 - val_loss: 0.4817 - val_acc: 0.8226\n",
      "Epoch 40/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.4463 - acc: 0.8249 - val_loss: 0.5503 - val_acc: 0.7993\n",
      "Epoch 41/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.4322 - acc: 0.8330 - val_loss: 0.3955 - val_acc: 0.8510\n",
      "Epoch 42/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.4217 - acc: 0.8292 - val_loss: 0.5102 - val_acc: 0.8286\n",
      "Epoch 43/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.4221 - acc: 0.8414 - val_loss: 0.4496 - val_acc: 0.8320\n",
      "Epoch 44/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.4000 - acc: 0.8438 - val_loss: 0.8308 - val_acc: 0.7192\n",
      "Epoch 45/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.4195 - acc: 0.8468 - val_loss: 0.4834 - val_acc: 0.8252\n",
      "Epoch 46/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.3759 - acc: 0.8611 - val_loss: 0.4257 - val_acc: 0.8562\n",
      "Epoch 47/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.3776 - acc: 0.8583 - val_loss: 0.4871 - val_acc: 0.8260\n",
      "Epoch 48/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.3774 - acc: 0.8583 - val_loss: 0.4110 - val_acc: 0.8407\n",
      "Epoch 49/100\n",
      "4642/4642 [==============================] - 2s 457us/step - loss: 0.3576 - acc: 0.8649 - val_loss: 0.3813 - val_acc: 0.8656\n",
      "Epoch 50/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.3822 - acc: 0.8524 - val_loss: 0.3707 - val_acc: 0.8760\n",
      "Epoch 51/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.3431 - acc: 0.8684 - val_loss: 0.3679 - val_acc: 0.8682\n",
      "Epoch 52/100\n",
      "4642/4642 [==============================] - 2s 457us/step - loss: 0.3579 - acc: 0.8634 - val_loss: 0.3750 - val_acc: 0.8587\n",
      "Epoch 53/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.3575 - acc: 0.8671 - val_loss: 0.4247 - val_acc: 0.8570\n",
      "Epoch 54/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.3260 - acc: 0.8763 - val_loss: 0.3559 - val_acc: 0.8803\n",
      "Epoch 55/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.3368 - acc: 0.8772 - val_loss: 0.4223 - val_acc: 0.8725\n",
      "Epoch 56/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.2930 - acc: 0.8921 - val_loss: 0.3430 - val_acc: 0.8863\n",
      "Epoch 57/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.3154 - acc: 0.8841 - val_loss: 0.4276 - val_acc: 0.8510\n",
      "Epoch 58/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.3061 - acc: 0.8880 - val_loss: 0.5464 - val_acc: 0.8234\n",
      "Epoch 59/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.3062 - acc: 0.8906 - val_loss: 0.4856 - val_acc: 0.8372\n",
      "Epoch 60/100\n",
      "4642/4642 [==============================] - 2s 463us/step - loss: 0.3004 - acc: 0.8875 - val_loss: 0.3471 - val_acc: 0.8854\n",
      "Epoch 61/100\n",
      "4642/4642 [==============================] - 2s 461us/step - loss: 0.2835 - acc: 0.8994 - val_loss: 0.3799 - val_acc: 0.8768\n",
      "Epoch 62/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 0.2901 - acc: 0.8908 - val_loss: 0.3627 - val_acc: 0.8786\n",
      "Epoch 63/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 0.2584 - acc: 0.9054 - val_loss: 0.4357 - val_acc: 0.8708\n",
      "Epoch 64/100\n",
      "4642/4642 [==============================] - 2s 454us/step - loss: 0.2713 - acc: 0.9044 - val_loss: 0.4008 - val_acc: 0.8699\n",
      "Epoch 65/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 0.2650 - acc: 0.9050 - val_loss: 0.4211 - val_acc: 0.8665\n",
      "Epoch 66/100\n",
      "4642/4642 [==============================] - 2s 463us/step - loss: 0.2690 - acc: 0.9028 - val_loss: 0.4550 - val_acc: 0.8570\n",
      "Epoch 67/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.2541 - acc: 0.9067 - val_loss: 0.4763 - val_acc: 0.8579\n",
      "Epoch 68/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.2500 - acc: 0.9115 - val_loss: 0.4448 - val_acc: 0.8605\n",
      "Epoch 69/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.2591 - acc: 0.9130 - val_loss: 0.4017 - val_acc: 0.8717\n",
      "Epoch 70/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.2475 - acc: 0.9143 - val_loss: 0.6326 - val_acc: 0.8140\n",
      "Epoch 71/100\n",
      "4642/4642 [==============================] - 2s 459us/step - loss: 0.2436 - acc: 0.9153 - val_loss: 0.5254 - val_acc: 0.8493\n",
      "Epoch 72/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.2388 - acc: 0.9158 - val_loss: 0.4176 - val_acc: 0.8760\n",
      "Epoch 73/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.2186 - acc: 0.9205 - val_loss: 0.3212 - val_acc: 0.9009\n",
      "Epoch 74/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 0.2285 - acc: 0.9227 - val_loss: 0.2773 - val_acc: 0.9190\n",
      "Epoch 75/100\n",
      "4642/4642 [==============================] - 2s 455us/step - loss: 0.2389 - acc: 0.9128 - val_loss: 0.4943 - val_acc: 0.8630\n",
      "Epoch 76/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 0.2139 - acc: 0.9283 - val_loss: 0.3775 - val_acc: 0.8949\n",
      "Epoch 77/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 0.2010 - acc: 0.9304 - val_loss: 0.6394 - val_acc: 0.8165\n",
      "Epoch 78/100\n",
      "4642/4642 [==============================] - 2s 455us/step - loss: 0.2047 - acc: 0.9302 - val_loss: 0.4721 - val_acc: 0.8699\n",
      "Epoch 79/100\n",
      "4642/4642 [==============================] - 2s 455us/step - loss: 0.2112 - acc: 0.9287 - val_loss: 0.4661 - val_acc: 0.8665\n",
      "Epoch 80/100\n",
      "4642/4642 [==============================] - 2s 454us/step - loss: 0.2135 - acc: 0.9278 - val_loss: 0.4396 - val_acc: 0.8846\n",
      "Epoch 81/100\n",
      "4642/4642 [==============================] - 2s 455us/step - loss: 0.2029 - acc: 0.9343 - val_loss: 0.4602 - val_acc: 0.8725\n",
      "Epoch 82/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.1901 - acc: 0.9326 - val_loss: 0.3718 - val_acc: 0.8898\n",
      "Epoch 83/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.1832 - acc: 0.9401 - val_loss: 0.3543 - val_acc: 0.8958\n",
      "Epoch 84/100\n",
      "4642/4642 [==============================] - 2s 456us/step - loss: 0.1899 - acc: 0.9349 - val_loss: 0.4349 - val_acc: 0.8872\n",
      "Epoch 85/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.1891 - acc: 0.9390 - val_loss: 0.4185 - val_acc: 0.8898\n",
      "Epoch 86/100\n",
      "4642/4642 [==============================] - 2s 460us/step - loss: 0.1783 - acc: 0.9369 - val_loss: 0.3737 - val_acc: 0.9018\n",
      "Epoch 87/100\n",
      "4642/4642 [==============================] - 2s 458us/step - loss: 0.1787 - acc: 0.9416 - val_loss: 0.3306 - val_acc: 0.9070\n",
      "Epoch 88/100\n",
      "4642/4642 [==============================] - 2s 468us/step - loss: 0.1728 - acc: 0.9410 - val_loss: 0.3658 - val_acc: 0.9001\n",
      "Epoch 89/100\n",
      "4642/4642 [==============================] - 2s 471us/step - loss: 0.1670 - acc: 0.9431 - val_loss: 0.3622 - val_acc: 0.8975\n",
      "Epoch 90/100\n",
      "4642/4642 [==============================] - 2s 465us/step - loss: 0.1741 - acc: 0.9425 - val_loss: 0.3731 - val_acc: 0.9027\n",
      "Epoch 91/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.1853 - acc: 0.9436 - val_loss: 0.3749 - val_acc: 0.9130\n",
      "Epoch 92/100\n",
      "4642/4642 [==============================] - 2s 463us/step - loss: 0.1671 - acc: 0.9464 - val_loss: 0.4217 - val_acc: 0.8915\n",
      "Epoch 93/100\n",
      "4642/4642 [==============================] - 2s 464us/step - loss: 0.1761 - acc: 0.9418 - val_loss: 0.3352 - val_acc: 0.9165\n",
      "Epoch 94/100\n",
      "4642/4642 [==============================] - 2s 466us/step - loss: 0.1499 - acc: 0.9515 - val_loss: 0.3687 - val_acc: 0.9070\n",
      "Epoch 95/100\n",
      "4642/4642 [==============================] - 2s 462us/step - loss: 0.1581 - acc: 0.9487 - val_loss: 0.3927 - val_acc: 0.8984\n",
      "Epoch 96/100\n",
      "4642/4642 [==============================] - 2s 466us/step - loss: 0.1542 - acc: 0.9479 - val_loss: 0.4239 - val_acc: 0.8665\n",
      "Epoch 97/100\n",
      "4642/4642 [==============================] - 2s 463us/step - loss: 0.1486 - acc: 0.9513 - val_loss: 0.3952 - val_acc: 0.8889\n",
      "Epoch 98/100\n",
      "4642/4642 [==============================] - 2s 464us/step - loss: 0.1475 - acc: 0.9517 - val_loss: 0.4630 - val_acc: 0.8906\n",
      "Epoch 99/100\n",
      "4642/4642 [==============================] - 2s 465us/step - loss: 0.1516 - acc: 0.9533 - val_loss: 0.4341 - val_acc: 0.8923\n",
      "Epoch 100/100\n",
      "4642/4642 [==============================] - 2s 464us/step - loss: 0.1550 - acc: 0.9487 - val_loss: 0.4326 - val_acc: 0.8854\n",
      "1517/1517 [==============================] - 1s 528us/step\n"
     ]
    }
   ],
   "source": [
    "batchSize = 100\n",
    "keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "model.fit(trainX,trainY, validation_split=1-trainSplitRatio,epochs=100,batch_size=batchSize,verbose=1)\n",
    "score = model.evaluate(testX,testY,verbose=1)\n",
    "model.save('tommyCUDACNNmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38723762703712, 0.89189189193118301]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1496, 18)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(testX)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9211229946524064\n"
     ]
    }
   ],
   "source": [
    "count = 0.0\n",
    "den = 0.0\n",
    "for pair in zip(predictions, testY):\n",
    "    if np.argmax(pair[0]) == np.argmax(pair[1]):\n",
    "        count += 1.0\n",
    "    den += 1.0\n",
    "\n",
    "print(count / den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv('preds_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_df = pd.DataFrame(testY)\n",
    "true_df.to_csv('true_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
